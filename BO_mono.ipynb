{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.000202762, -0.0456457]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import io\n",
    "import os\n",
    "from math import log\n",
    "import json\n",
    "from botorch.models import SingleTaskGP, FixedNoiseGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition.multi_objective import ExpectedHypervolumeImprovement\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "import asyncio\n",
    "dtype = torch.float64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def x_to_filename(x):\n",
    "    return f'{x[0]}_{x[1]}_{x[2]}_{x[3]}.json'\n",
    "\n",
    "def filename_to_x(filename):\n",
    "    return [float(x) for x in filename[:-5].split('_')]\n",
    "\n",
    "NUM_CORES=14\n",
    "running_tasks={}\n",
    "async def wait_for_core_to_be_available():\n",
    "    while len(running_tasks)>NUM_CORES:\n",
    "        await asyncio.sleep(1.0)\n",
    "\n",
    "async def evaluate_profile(x):\n",
    "    await wait_for_core_to_be_available()\n",
    "    filename=x_to_filename(x)\n",
    "    running_tasks[filename]=True\n",
    "    #display(filename)\n",
    "    existing_result_files=os.listdir(\"case/results\")\n",
    "    existing_results_x=[filename_to_x(filename) for filename in existing_result_files]\n",
    "    distances=[torch.dist(torch.tensor(x),torch.tensor(existing_x)).item() for existing_x in existing_results_x]\n",
    "    #display(distances)\n",
    "    if len(distances)==0 or min(distances)>0.001:\n",
    "        config=json.dumps({\n",
    "            'p':x[0],\n",
    "            'm':x[1],\n",
    "            't':x[2],\n",
    "            'a':x[3]\n",
    "        })\n",
    "        p=await asyncio.create_subprocess_shell(f'cd case; ./evaluate_airfoil.sh \\'{config}\\'',stdout=asyncio.subprocess.PIPE)\n",
    "        await p.wait()\n",
    "        #os.system(f'cd case; ./evaluate_airfoil.sh \\'{config}\\'')\n",
    "    existing_result_files=os.listdir(\"case/results\")\n",
    "    existing_results_x=[filename_to_x(filename) for filename in existing_result_files]\n",
    "    distances=[torch.dist(torch.tensor(x),torch.tensor(existing_x)).item() for existing_x in existing_results_x]\n",
    "    min_distance_index=distances.index(min(distances))\n",
    "    with open(\"case/results/\"+existing_result_files[min_distance_index]) as file:\n",
    "        result=json.load(file)\n",
    "        if abs(result['C_L'])>100:\n",
    "            return [-2.0,2.0]\n",
    "        #display(result)\n",
    "        running_tasks.pop(filename)\n",
    "        return [result['C_L'],-result['C_D']]\n",
    "await evaluate_profile([0.3,0.0,0.12,0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_lims=[(0.1,0.9),(-0.2,0.2),(0.05,0.3),(0.01,35)]\n",
    "\n",
    "random_initial_X=False\n",
    "INITIAL_X_COUNT=100\n",
    "initial_X = None\n",
    "if random_initial_X or len(os.listdir(\"case/results_random\"))<INITIAL_X_COUNT:\n",
    "    initial_X = torch.rand(INITIAL_X_COUNT,4, dtype=dtype, device=device)\n",
    "    for d in range(4):\n",
    "        initial_X[:,d]=x_lims[d][0]+initial_X[:,d]*(x_lims[d][1]-x_lims[d][0])\n",
    "else:\n",
    "    # get initial X from filenames in case/results folder\n",
    "    initial_X=torch.tensor([filename_to_x(filename) for filename in os.listdir(\"case/results_random\")],dtype=dtype,device=device)\n",
    "    # take six random points from the initial X\n",
    "    initial_X = initial_X[torch.randperm(initial_X.shape[0])[:INITIAL_X_COUNT]]\n",
    "\n",
    "#display(initial_X)\n",
    "y=await asyncio.gather(*[evaluate_profile(x.tolist()) for x in initial_X])\n",
    "train_X=initial_X\n",
    "train_Y = torch.tensor(y,dtype=dtype,device=device)\n",
    "import plotting\n",
    "plotting.plot_population(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitted_model(X,Y):\n",
    "    train_Yvar = torch.full_like(Y, 0.01)\n",
    "    gp= FixedNoiseGP(X, Y, train_Yvar)\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights= tensor([[0.6231, 0.3769],\n",
      "        [0.1338, 0.8662],\n",
      "        [0.2981, 0.7019],\n",
      "        [0.8130, 0.1870],\n",
      "        [0.7857, 0.2143],\n",
      "        [0.7942, 0.2058]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.1254, -0.1440, -0.3790, -0.4449, -0.6195, -0.4625, -0.3206, -0.4238,\n",
       "        -0.2280, -0.3194, -0.5587, -0.4626, -0.0672, -0.0814, -0.5285, -0.3697,\n",
       "        -0.1149, -0.0147, -0.1898, -0.2565, -0.4537, -0.1081, -0.4924, -0.3408,\n",
       "        -0.2763, -0.4366, -0.1411, -0.3369, -0.1404, -0.2688, -0.4771, -0.1974,\n",
       "        -0.3444, -0.2836, -0.5063, -0.1293, -0.3121, -0.4676, -0.1011, -0.4475,\n",
       "        -0.4524, -0.3055, -0.3008, -0.0559, -0.2568, -0.1123, -0.1050, -0.4826,\n",
       "        -0.4863, -0.6231, -0.3151, -0.5189, -0.3549, -0.5355, -0.2133, -0.4814,\n",
       "        -0.0990, -0.3301, -0.0570, -0.4483, -0.5079, -0.4666, -0.4872, -0.1768,\n",
       "        -0.0806, -0.2064, -0.0999, -0.3506, -0.1908, -0.1622, -0.0946, -0.1477,\n",
       "        -0.3818, -0.3829, -0.4241, -0.0523, -0.0289, -0.1544, -0.0765, -0.2040,\n",
       "        -0.2684, -0.3456, -0.1199, -0.0895, -0.4767, -0.1257, -0.1244, -0.3166,\n",
       "        -0.4293, -0.0157, -0.2735, -0.5369, -0.6047, -0.4209, -0.0168, -0.0077,\n",
       "        -0.4121, -0.5496, -0.1309, -0.0449], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3923]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.7938,  0.2000,  0.1330, 19.9163], dtype=torch.float64)  with expected improvement 0.008460668062768536  and expected value of  tensor([[-0.0624]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.06917649105482358]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0904, -0.1768, -0.2359, -0.6491, -0.2659, -0.1634, -0.0689, -0.5916,\n",
       "        -0.0896, -0.1786, -0.3607, -0.0993, -0.1545, -0.0255, -0.6065, -0.1677,\n",
       "        -0.0855, -0.0032, -0.1538, -0.0551, -0.7834, -0.1396, -0.2396, -0.2669,\n",
       "        -0.4063, -0.5903, -0.1875, -0.1428, -0.1378, -0.0894, -0.7636, -0.1228,\n",
       "        -0.4066, -0.0609, -0.2818, -0.0894, -0.4187, -0.3430, -0.0520, -0.7823,\n",
       "        -0.3535, -0.2548, -0.3735, -0.0120, -0.0682, -0.1181, -0.1129, -0.1184,\n",
       "        -0.5671, -0.2741, -0.1491, -0.5688, -0.5261, -0.8662, -0.1075, -0.3707,\n",
       "        -0.1715, -0.4423, -0.0924, -0.5551, -0.1091, -0.8364, -0.7498, -0.1606,\n",
       "        -0.0731, -0.1112, -0.0245, -0.1170, -0.1496, -0.1189, -0.0561, -0.0796,\n",
       "        -0.4620, -0.6251, -0.2518, -0.0153, -0.0079, -0.1406, -0.0843, -0.2176,\n",
       "        -0.3055, -0.4960, -0.0977, -0.0395, -0.1138, -0.1161, -0.1124, -0.1430,\n",
       "        -0.4769, -0.0127, -0.2649, -0.1344, -0.1298, -0.1495, -0.0386, -0.0177,\n",
       "        -0.1377, -0.4587, -0.0620, -0.0632], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1410]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.8690,  0.1792,  0.3000, 23.3488], dtype=torch.float64)  with expected improvement 0.015060063199863841  and expected value of  tensor([[-0.0606]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.09240507333700805]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0732, -0.1433, -0.1912, -0.5259, -0.2964, -0.2213, -0.1534, -0.4794,\n",
       "        -0.1091, -0.1528, -0.2923, -0.2213, -0.1252, -0.0390, -0.4915, -0.1769,\n",
       "        -0.0693, -0.0071, -0.1247, -0.1228, -0.6348, -0.1131, -0.2356, -0.2163,\n",
       "        -0.3292, -0.4783, -0.1519, -0.1612, -0.1116, -0.1286, -0.6187, -0.0995,\n",
       "        -0.3295, -0.1357, -0.2422, -0.0724, -0.3392, -0.2779, -0.0484, -0.6339,\n",
       "        -0.2865, -0.2065, -0.3026, -0.0267, -0.1229, -0.0957, -0.0915, -0.2309,\n",
       "        -0.4595, -0.2981, -0.1508, -0.4609, -0.4263, -0.7019, -0.1020, -0.3004,\n",
       "        -0.1390, -0.3584, -0.0749, -0.4498, -0.2430, -0.6777, -0.6076, -0.1301,\n",
       "        -0.0593, -0.0987, -0.0478, -0.1677, -0.1212, -0.0963, -0.0454, -0.0707,\n",
       "        -0.3743, -0.5065, -0.2041, -0.0250, -0.0138, -0.1139, -0.0683, -0.1763,\n",
       "        -0.2475, -0.4019, -0.0791, -0.0428, -0.2281, -0.0940, -0.0911, -0.1515,\n",
       "        -0.3864, -0.0103, -0.2147, -0.2569, -0.2893, -0.2014, -0.0313, -0.0143,\n",
       "        -0.1972, -0.3717, -0.0626, -0.0512], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2124]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.8846,  0.1632,  0.1120, 19.7402], dtype=torch.float64)  with expected improvement 0.011730287213705035  and expected value of  tensor([[-0.0479]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.06880406765177716]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.1636, -0.1879, -0.4945, -0.5805, -0.8084, -0.6036, -0.4184, -0.5530,\n",
       "        -0.2975, -0.4168, -0.7290, -0.6036, -0.0541, -0.1063, -0.6896, -0.4825,\n",
       "        -0.1499, -0.0192, -0.2477, -0.3348, -0.5920, -0.1410, -0.6425, -0.4447,\n",
       "        -0.3605, -0.5697, -0.1842, -0.4397, -0.1832, -0.3508, -0.6226, -0.2576,\n",
       "        -0.4494, -0.3700, -0.6606, -0.1687, -0.4072, -0.6101, -0.1319, -0.5840,\n",
       "        -0.5903, -0.3986, -0.3925, -0.0729, -0.3351, -0.1465, -0.1370, -0.6297,\n",
       "        -0.6345, -0.8130, -0.4112, -0.6771, -0.4631, -0.6988, -0.2783, -0.6281,\n",
       "        -0.1292, -0.4307, -0.0744, -0.5850, -0.6627, -0.6088, -0.6357, -0.2308,\n",
       "        -0.1051, -0.2693, -0.1304, -0.4575, -0.2490, -0.2116, -0.1234, -0.1927,\n",
       "        -0.4982, -0.4997, -0.5534, -0.0683, -0.0377, -0.2015, -0.0999, -0.2663,\n",
       "        -0.3502, -0.4509, -0.1565, -0.1168, -0.6220, -0.1640, -0.1623, -0.4132,\n",
       "        -0.5602, -0.0204, -0.3568, -0.7006, -0.7890, -0.5492, -0.0167, -0.0038,\n",
       "        -0.5378, -0.7171, -0.1708, -0.0586], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5283]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.7932,  0.2000,  0.1530, 23.5940], dtype=torch.float64)  with expected improvement 0.010702716998562118  and expected value of  tensor([[-0.0675]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.0834397835232907]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.1581, -0.1816, -0.4779, -0.5610, -0.7813, -0.5833, -0.4043, -0.5345,\n",
       "        -0.2875, -0.4028, -0.7045, -0.5833, -0.0523, -0.1027, -0.6664, -0.4662,\n",
       "        -0.1449, -0.0186, -0.2393, -0.3235, -0.5721, -0.1363, -0.6209, -0.4297,\n",
       "        -0.3484, -0.5506, -0.1780, -0.4249, -0.1770, -0.3390, -0.6016, -0.2489,\n",
       "        -0.4343, -0.3576, -0.6384, -0.1630, -0.3935, -0.5896, -0.1275, -0.5643,\n",
       "        -0.5705, -0.3852, -0.3793, -0.0705, -0.3238, -0.1416, -0.1324, -0.6085,\n",
       "        -0.6132, -0.7857, -0.3973, -0.6543, -0.4475, -0.6753, -0.2689, -0.6070,\n",
       "        -0.1249, -0.4163, -0.0719, -0.5654, -0.6405, -0.5884, -0.6144, -0.2230,\n",
       "        -0.1016, -0.2602, -0.1260, -0.4421, -0.2407, -0.2045, -0.1193, -0.1862,\n",
       "        -0.4814, -0.4829, -0.5348, -0.0660, -0.0364, -0.1947, -0.0965, -0.2573,\n",
       "        -0.3384, -0.4358, -0.1512, -0.1129, -0.6011, -0.1585, -0.1569, -0.3993,\n",
       "        -0.5413, -0.0197, -0.3448, -0.6771, -0.7625, -0.5307, -0.0162, -0.0044,\n",
       "        -0.5197, -0.6930, -0.1650, -0.0566], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5087]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.7838,  0.2000,  0.1524, 23.6376], dtype=torch.float64)  with expected improvement 0.01042507717858326  and expected value of  tensor([[-0.0673]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.081947774991236]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.1598, -0.1836, -0.4831, -0.5670, -0.7897, -0.5896, -0.4087, -0.5403,\n",
       "        -0.2906, -0.4072, -0.7122, -0.5897, -0.0529, -0.1038, -0.6736, -0.4713,\n",
       "        -0.1465, -0.0188, -0.2419, -0.3270, -0.5783, -0.1378, -0.6276, -0.4344,\n",
       "        -0.3521, -0.5566, -0.1799, -0.4295, -0.1789, -0.3427, -0.6082, -0.2516,\n",
       "        -0.4390, -0.3615, -0.6453, -0.1648, -0.3978, -0.5960, -0.1289, -0.5705,\n",
       "        -0.5767, -0.3894, -0.3834, -0.0712, -0.3273, -0.1432, -0.1338, -0.6151,\n",
       "        -0.6198, -0.7942, -0.4016, -0.6614, -0.4524, -0.6826, -0.2719, -0.6136,\n",
       "        -0.1262, -0.4208, -0.0727, -0.5715, -0.6474, -0.5948, -0.6210, -0.2254,\n",
       "        -0.1027, -0.2631, -0.1274, -0.4469, -0.2433, -0.2067, -0.1205, -0.1882,\n",
       "        -0.4866, -0.4881, -0.5406, -0.0667, -0.0368, -0.1968, -0.0976, -0.2601,\n",
       "        -0.3421, -0.4405, -0.1528, -0.1141, -0.6076, -0.1602, -0.1586, -0.4036,\n",
       "        -0.5472, -0.0200, -0.3486, -0.6844, -0.7708, -0.5365, -0.0163, -0.0042,\n",
       "        -0.5253, -0.7005, -0.1668, -0.0572], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5148]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.7868,  0.2000,  0.1526, 23.6240], dtype=torch.float64)  with expected improvement 0.010512100239645387  and expected value of  tensor([[-0.0673]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.08241469376504847]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Cannot apply Blossom: odd number of triangles (109591) in surface 1\n",
      "Warning : Cannot apply Blossom: odd number of triangles (112009) in surface 1\n",
      "Warning : Cannot apply Blossom: odd number of triangles (155953) in surface 1\n",
      "Warning : ------------------------------\n",
      "Warning : Mesh generation error summary\n",
      "Warning :     1 warning\n",
      "Warning :     0 errors\n",
      "Warning : Check the full log for details\n",
      "Warning : ------------------------------\n",
      "Warning : ------------------------------\n",
      "Warning : Mesh generation error summary\n",
      "Warning :     1 warning\n",
      "Warning :     0 errors\n",
      "Warning : Check the full log for details\n",
      "Warning : ------------------------------\n",
      "Warning : ------------------------------\n",
      "Warning : Mesh generation error summary\n",
      "Warning :     1 warning\n",
      "Warning :     0 errors\n",
      "Warning : Check the full log for details\n",
      "Warning : ------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective results= [[2.46906, -0.11511], [2.64462, -0.0409219], [2.39698, -0.120333], [2.60231, -0.061409], [2.63166, -0.0582962], [2.51895, -0.0450821]]\n",
      "actual value= tensor(-0.0298, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.0256, dtype=torch.float64)\n",
      "actual value= tensor(5.8083e-05, dtype=torch.float64)\n",
      "actual improvement= tensor(0.0043, dtype=torch.float64)\n",
      "actual value= tensor(-0.0448, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.0406, dtype=torch.float64)\n",
      "actual value= tensor(-0.0091, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.0049, dtype=torch.float64)\n",
      "actual value= tensor(-0.0025, dtype=torch.float64)\n",
      "actual improvement= tensor(0.0017, dtype=torch.float64)\n",
      "actual value= tensor(-0.0271, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.0229, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.1256, -0.1442, -0.3791, -0.4449, -0.6195, -0.4626, -0.3208, -0.4239,\n",
       "        -0.2282, -0.3196, -0.5587, -0.4627, -0.0707, -0.0817, -0.5285, -0.3698,\n",
       "        -0.1151, -0.0150, -0.1900, -0.2567, -0.4537, -0.1083, -0.4924, -0.3409,\n",
       "        -0.2764, -0.4367, -0.1414, -0.3371, -0.1406, -0.2690, -0.4772, -0.1976,\n",
       "        -0.3445, -0.2837, -0.5063, -0.1295, -0.3122, -0.4676, -0.1013, -0.4476,\n",
       "        -0.4525, -0.3056, -0.3010, -0.0561, -0.2570, -0.1125, -0.1052, -0.4826,\n",
       "        -0.4863, -0.6231, -0.3152, -0.5189, -0.3550, -0.5356, -0.2135, -0.4814,\n",
       "        -0.0992, -0.3302, -0.0573, -0.4484, -0.5079, -0.4667, -0.4872, -0.1770,\n",
       "        -0.0808, -0.2065, -0.1001, -0.3507, -0.1910, -0.1624, -0.0948, -0.1479,\n",
       "        -0.3819, -0.3830, -0.4242, -0.0526, -0.0291, -0.1546, -0.0768, -0.2042,\n",
       "        -0.2685, -0.3457, -0.1201, -0.0898, -0.4768, -0.1259, -0.1246, -0.3168,\n",
       "        -0.4294, -0.0159, -0.2736, -0.5370, -0.6047, -0.4210, -0.0209, -0.0119,\n",
       "        -0.4122, -0.5496, -0.1311, -0.0452, -0.0300,  0.0000, -0.0424, -0.0072,\n",
       "        -0.0061, -0.0215], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3931]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.7503,  0.2000,  0.3000, 22.0683], dtype=torch.float64)  with expected improvement 0.009088071671658537  and expected value of  tensor([[-0.0326]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.054112725935600514]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0991, -0.1846, -0.2430, -0.6515, -0.2727, -0.1713, -0.0689, -0.5947,\n",
       "        -0.0983, -0.1864, -0.3664, -0.0993, -0.1625, -0.0350, -0.6094, -0.1755,\n",
       "        -0.0943, -0.0109, -0.1619, -0.0602, -0.7843, -0.1478, -0.2467, -0.2736,\n",
       "        -0.4115, -0.5934, -0.1951, -0.1509, -0.1459, -0.0982, -0.7647, -0.1312,\n",
       "        -0.4117, -0.0609, -0.2884, -0.0981, -0.4237, -0.3489, -0.0611, -0.7832,\n",
       "        -0.3593, -0.2617, -0.3790, -0.0121, -0.0772, -0.1265, -0.1213, -0.1268,\n",
       "        -0.5705, -0.2808, -0.1572, -0.5721, -0.5300, -0.8662, -0.1160, -0.3763,\n",
       "        -0.1793, -0.4470, -0.1011, -0.5586, -0.1091, -0.8367, -0.7511, -0.1685,\n",
       "        -0.0820, -0.1197, -0.0340, -0.1254, -0.1576, -0.1273, -0.0652, -0.0884,\n",
       "        -0.4665, -0.6278, -0.2587, -0.0248, -0.0176, -0.1487, -0.0931, -0.2249,\n",
       "        -0.3118, -0.5001, -0.1063, -0.0488, -0.1223, -0.1245, -0.1209, -0.1511,\n",
       "        -0.4812, -0.0222, -0.2717, -0.1427, -0.1299, -0.1576, -0.0479, -0.0272,\n",
       "        -0.1459, -0.4633, -0.0710, -0.0722, -0.0602,  0.0000, -0.0644, -0.0166,\n",
       "        -0.0141, -0.0046], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1443]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.7082,  0.1684,  0.3000, 24.8019], dtype=torch.float64)  with expected improvement 0.013503145528086548  and expected value of  tensor([[-0.0255]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.06053004077284935]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0803, -0.1496, -0.1969, -0.5279, -0.2964, -0.2213, -0.1535, -0.4819,\n",
       "        -0.1092, -0.1529, -0.2969, -0.2214, -0.1317, -0.0391, -0.4938, -0.1770,\n",
       "        -0.0764, -0.0088, -0.1311, -0.1228, -0.6355, -0.1197, -0.2356, -0.2217,\n",
       "        -0.3334, -0.4808, -0.1581, -0.1613, -0.1183, -0.1287, -0.6197, -0.1063,\n",
       "        -0.3336, -0.1358, -0.2423, -0.0795, -0.3433, -0.2827, -0.0495, -0.6346,\n",
       "        -0.2911, -0.2121, -0.3071, -0.0269, -0.1230, -0.1025, -0.0983, -0.2309,\n",
       "        -0.4623, -0.2981, -0.1508, -0.4636, -0.4294, -0.7019, -0.1021, -0.3049,\n",
       "        -0.1453, -0.3622, -0.0819, -0.4526, -0.2430, -0.6780, -0.6087, -0.1365,\n",
       "        -0.0665, -0.0988, -0.0479, -0.1678, -0.1277, -0.1031, -0.0528, -0.0716,\n",
       "        -0.3780, -0.5087, -0.2097, -0.0252, -0.0142, -0.1205, -0.0755, -0.1822,\n",
       "        -0.2526, -0.4052, -0.0861, -0.0430, -0.2281, -0.1009, -0.0979, -0.1516,\n",
       "        -0.3899, -0.0180, -0.2201, -0.2569, -0.2893, -0.2014, -0.0388, -0.0221,\n",
       "        -0.1972, -0.3754, -0.0627, -0.0585, -0.0488,  0.0000, -0.0522, -0.0135,\n",
       "        -0.0114, -0.0103], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2127]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.6643,  0.1728,  0.3000, 25.0197], dtype=torch.float64)  with expected improvement 0.010693667890363714  and expected value of  tensor([[-0.0301]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.056712201440949225]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.1639, -0.1882, -0.4946, -0.5806, -0.8084, -0.6036, -0.4186, -0.5532,\n",
       "        -0.2977, -0.4170, -0.7291, -0.6037, -0.0545, -0.1066, -0.6896, -0.4826,\n",
       "        -0.1502, -0.0196, -0.2479, -0.3350, -0.5921, -0.1413, -0.6425, -0.4448,\n",
       "        -0.3607, -0.5698, -0.1845, -0.4398, -0.1834, -0.3510, -0.6226, -0.2578,\n",
       "        -0.4495, -0.3702, -0.6607, -0.1689, -0.4074, -0.6102, -0.1322, -0.5841,\n",
       "        -0.5904, -0.3988, -0.3927, -0.0732, -0.3353, -0.1468, -0.1373, -0.6298,\n",
       "        -0.6346, -0.8130, -0.4113, -0.6771, -0.4632, -0.6988, -0.2785, -0.6282,\n",
       "        -0.1295, -0.4309, -0.0747, -0.5851, -0.6628, -0.6089, -0.6358, -0.2310,\n",
       "        -0.1054, -0.2695, -0.1307, -0.4576, -0.2493, -0.2119, -0.1237, -0.1930,\n",
       "        -0.4983, -0.4998, -0.5535, -0.0686, -0.0380, -0.2017, -0.1002, -0.2665,\n",
       "        -0.3504, -0.4511, -0.1568, -0.1171, -0.6221, -0.1642, -0.1626, -0.4133,\n",
       "        -0.5603, -0.0208, -0.3570, -0.7007, -0.7891, -0.5493, -0.0171, -0.0059,\n",
       "        -0.5379, -0.7172, -0.1710, -0.0589, -0.0392,  0.0000, -0.0553, -0.0094,\n",
       "        -0.0030, -0.0281], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5290]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.7606,  0.2000,  0.3000, 22.0717], dtype=torch.float64)  with expected improvement 0.01103168050078431  and expected value of  tensor([[-0.0305]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.058078043373713126]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.1583, -0.1819, -0.4780, -0.5611, -0.7813, -0.5834, -0.4045, -0.5346,\n",
       "        -0.2877, -0.4030, -0.7046, -0.5834, -0.0526, -0.1030, -0.6664, -0.4664,\n",
       "        -0.1452, -0.0189, -0.2396, -0.3237, -0.5722, -0.1366, -0.6209, -0.4299,\n",
       "        -0.3486, -0.5507, -0.1783, -0.4251, -0.1773, -0.3392, -0.6017, -0.2492,\n",
       "        -0.4344, -0.3578, -0.6385, -0.1633, -0.3937, -0.5897, -0.1278, -0.5644,\n",
       "        -0.5706, -0.3854, -0.3795, -0.0708, -0.3240, -0.1419, -0.1327, -0.6086,\n",
       "        -0.6133, -0.7857, -0.3975, -0.6544, -0.4477, -0.6754, -0.2692, -0.6071,\n",
       "        -0.1251, -0.4164, -0.0722, -0.5654, -0.6405, -0.5885, -0.6144, -0.2232,\n",
       "        -0.1019, -0.2605, -0.1263, -0.4422, -0.2409, -0.2048, -0.1195, -0.1865,\n",
       "        -0.4815, -0.4830, -0.5349, -0.0663, -0.0367, -0.1950, -0.0968, -0.2575,\n",
       "        -0.3386, -0.4359, -0.1515, -0.1132, -0.6012, -0.1587, -0.1572, -0.3994,\n",
       "        -0.5414, -0.0201, -0.3450, -0.6771, -0.7625, -0.5309, -0.0165, -0.0067,\n",
       "        -0.5198, -0.6931, -0.1653, -0.0569, -0.0379,  0.0000, -0.0534, -0.0091,\n",
       "        -0.0035, -0.0271], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5095]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.7582,  0.2000,  0.3000, 22.0671], dtype=torch.float64)  with expected improvement 0.010813442522512075  and expected value of  tensor([[-0.0306]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.05752676017138966]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.1601, -0.1839, -0.4832, -0.5671, -0.7897, -0.5897, -0.4089, -0.5404,\n",
       "        -0.2909, -0.4073, -0.7122, -0.5897, -0.0532, -0.1041, -0.6737, -0.4714,\n",
       "        -0.1467, -0.0191, -0.2422, -0.3272, -0.5784, -0.1381, -0.6277, -0.4345,\n",
       "        -0.3523, -0.5567, -0.1802, -0.4297, -0.1792, -0.3429, -0.6082, -0.2519,\n",
       "        -0.4391, -0.3617, -0.6454, -0.1650, -0.3980, -0.5961, -0.1292, -0.5706,\n",
       "        -0.5768, -0.3896, -0.3836, -0.0715, -0.3275, -0.1434, -0.1341, -0.6152,\n",
       "        -0.6199, -0.7942, -0.4018, -0.6615, -0.4525, -0.6827, -0.2721, -0.6137,\n",
       "        -0.1265, -0.4209, -0.0730, -0.5716, -0.6475, -0.5948, -0.6211, -0.2257,\n",
       "        -0.1030, -0.2633, -0.1277, -0.4470, -0.2435, -0.2070, -0.1208, -0.1885,\n",
       "        -0.4868, -0.4882, -0.5407, -0.0670, -0.0371, -0.1971, -0.0979, -0.2603,\n",
       "        -0.3423, -0.4407, -0.1531, -0.1144, -0.6077, -0.1605, -0.1589, -0.4038,\n",
       "        -0.5473, -0.0203, -0.3488, -0.6844, -0.7708, -0.5366, -0.0167, -0.0065,\n",
       "        -0.5255, -0.7006, -0.1671, -0.0576, -0.0383,  0.0000, -0.0540, -0.0092,\n",
       "        -0.0033, -0.0274], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5156]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.7590,  0.2000,  0.3000, 22.0685], dtype=torch.float64)  with expected improvement 0.010882298738215439  and expected value of  tensor([[-0.0306]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.05769907019141742]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective results= [[2.54231, -0.0728878], [2.54365, -0.0363276], [2.53892, -0.0300713], [2.59021, -0.0674745], [0.66566, -0.157429], [2.54293, -0.0675877]]\n",
      "actual value= tensor(-0.0175, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.0175, dtype=torch.float64)\n",
      "actual value= tensor(-0.0037, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.0037, dtype=torch.float64)\n",
      "actual value= tensor(-0.0087, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.0087, dtype=torch.float64)\n",
      "actual value= tensor(-0.0121, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.0121, dtype=torch.float64)\n",
      "actual value= tensor(-0.4271, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.4271, dtype=torch.float64)\n",
      "actual value= tensor(-0.0222, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.0222, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.1256, -0.1442, -0.3791, -0.4449, -0.6195, -0.4626, -0.3208, -0.4239,\n",
       "        -0.2282, -0.3196, -0.5587, -0.4627, -0.0738, -0.0817, -0.5285, -0.3698,\n",
       "        -0.1151, -0.0150, -0.1900, -0.2567, -0.4537, -0.1083, -0.4924, -0.3409,\n",
       "        -0.2764, -0.4367, -0.1414, -0.3371, -0.1406, -0.2690, -0.4772, -0.1976,\n",
       "        -0.3445, -0.2837, -0.5063, -0.1295, -0.3122, -0.4676, -0.1013, -0.4476,\n",
       "        -0.4525, -0.3056, -0.3010, -0.0561, -0.2570, -0.1125, -0.1052, -0.4826,\n",
       "        -0.4863, -0.6231, -0.3152, -0.5189, -0.3550, -0.5356, -0.2135, -0.4814,\n",
       "        -0.0992, -0.3302, -0.0573, -0.4484, -0.5079, -0.4667, -0.4872, -0.1770,\n",
       "        -0.0808, -0.2065, -0.1001, -0.3507, -0.1910, -0.1624, -0.0948, -0.1479,\n",
       "        -0.3819, -0.3830, -0.4242, -0.0526, -0.0291, -0.1546, -0.0768, -0.2042,\n",
       "        -0.2685, -0.3457, -0.1201, -0.0898, -0.4768, -0.1259, -0.1246, -0.3168,\n",
       "        -0.4294, -0.0159, -0.2736, -0.5370, -0.6047, -0.4210, -0.0244, -0.0155,\n",
       "        -0.4122, -0.5496, -0.1311, -0.0452, -0.0300, -0.0038, -0.0424, -0.0110,\n",
       "        -0.0099, -0.0215, -0.0175, -0.0173, -0.0181, -0.0131, -0.3387, -0.0174],\n",
       "       dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3930]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.6053,  0.2000,  0.0744, 25.4045], dtype=torch.float64)  with expected improvement 0.009889962082462293  and expected value of  tensor([[-0.0365]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.05655263117015427]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.1068, -0.1914, -0.2493, -0.6537, -0.2787, -0.1783, -0.0689, -0.5974,\n",
       "        -0.1061, -0.1932, -0.3714, -0.0993, -0.1696, -0.0434, -0.6120, -0.1825,\n",
       "        -0.1020, -0.0195, -0.1689, -0.0683, -0.7851, -0.1550, -0.2529, -0.2796,\n",
       "        -0.4161, -0.5962, -0.2019, -0.1581, -0.1532, -0.1059, -0.7658, -0.1386,\n",
       "        -0.4163, -0.0667, -0.2942, -0.1059, -0.4281, -0.3541, -0.0692, -0.7841,\n",
       "        -0.3644, -0.2678, -0.3839, -0.0184, -0.0851, -0.1339, -0.1288, -0.1343,\n",
       "        -0.5734, -0.2867, -0.1643, -0.5751, -0.5333, -0.8662, -0.1235, -0.3812,\n",
       "        -0.1862, -0.4513, -0.1088, -0.5617, -0.1091, -0.8370, -0.7523, -0.1755,\n",
       "        -0.0899, -0.1272, -0.0424, -0.1328, -0.1647, -0.1347, -0.0733, -0.0962,\n",
       "        -0.4705, -0.6302, -0.2648, -0.0333, -0.0261, -0.1559, -0.1009, -0.2313,\n",
       "        -0.3174, -0.5038, -0.1139, -0.0570, -0.1298, -0.1320, -0.1284, -0.1583,\n",
       "        -0.4851, -0.0307, -0.2776, -0.1500, -0.1299, -0.1647, -0.0561, -0.0357,\n",
       "        -0.1532, -0.4674, -0.0790, -0.0802, -0.0683, -0.0087, -0.0725, -0.0252,\n",
       "        -0.0227, -0.0121, -0.0344, -0.0050, -0.0039, -0.0300, -0.1023, -0.0301],\n",
       "       dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1479]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.9000,  0.1983,  0.3000, 25.1721], dtype=torch.float64)  with expected improvement 0.010433095160538483  and expected value of  tensor([[-0.0371]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.05857850356078085]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0865, -0.1551, -0.2020, -0.5297, -0.2964, -0.2213, -0.1535, -0.4841,\n",
       "        -0.1092, -0.1565, -0.3009, -0.2214, -0.1374, -0.0391, -0.4959, -0.1770,\n",
       "        -0.0827, -0.0158, -0.1369, -0.1228, -0.6362, -0.1256, -0.2356, -0.2265,\n",
       "        -0.3371, -0.4831, -0.1636, -0.1613, -0.1241, -0.1287, -0.6205, -0.1123,\n",
       "        -0.3373, -0.1358, -0.2423, -0.0858, -0.3469, -0.2869, -0.0561, -0.6353,\n",
       "        -0.2953, -0.2170, -0.3111, -0.0269, -0.1230, -0.1085, -0.1044, -0.2309,\n",
       "        -0.4647, -0.2981, -0.1508, -0.4660, -0.4322, -0.7019, -0.1021, -0.3089,\n",
       "        -0.1509, -0.3657, -0.0882, -0.4551, -0.2430, -0.6782, -0.6096, -0.1422,\n",
       "        -0.0729, -0.1031, -0.0479, -0.1678, -0.1335, -0.1091, -0.0594, -0.0780,\n",
       "        -0.3813, -0.5106, -0.2146, -0.0270, -0.0212, -0.1264, -0.0818, -0.1874,\n",
       "        -0.2572, -0.4082, -0.0923, -0.0462, -0.2281, -0.1069, -0.1040, -0.1516,\n",
       "        -0.3931, -0.0249, -0.2250, -0.2569, -0.2893, -0.2014, -0.0455, -0.0289,\n",
       "        -0.1972, -0.3787, -0.0640, -0.0650, -0.0553, -0.0071, -0.0587, -0.0204,\n",
       "        -0.0184, -0.0103, -0.0279, -0.0083, -0.0087, -0.0243, -0.1620, -0.0244],\n",
       "       dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2138]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.5123,  0.1763,  0.3000, 25.4439], dtype=torch.float64)  with expected improvement 0.009765023829009341  and expected value of  tensor([[-0.0302]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.047970525556853855]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.1639, -0.1882, -0.4946, -0.5806, -0.8084, -0.6036, -0.4186, -0.5532,\n",
       "        -0.2977, -0.4170, -0.7291, -0.6037, -0.0545, -0.1066, -0.6896, -0.4826,\n",
       "        -0.1502, -0.0196, -0.2479, -0.3350, -0.5921, -0.1413, -0.6425, -0.4448,\n",
       "        -0.3607, -0.5698, -0.1845, -0.4398, -0.1834, -0.3510, -0.6226, -0.2578,\n",
       "        -0.4495, -0.3702, -0.6607, -0.1689, -0.4074, -0.6102, -0.1322, -0.5841,\n",
       "        -0.5904, -0.3988, -0.3927, -0.0732, -0.3353, -0.1468, -0.1373, -0.6298,\n",
       "        -0.6346, -0.8130, -0.4113, -0.6771, -0.4632, -0.6988, -0.2785, -0.6282,\n",
       "        -0.1295, -0.4309, -0.0747, -0.5851, -0.6628, -0.6089, -0.6358, -0.2310,\n",
       "        -0.1054, -0.2695, -0.1307, -0.4576, -0.2493, -0.2119, -0.1237, -0.1930,\n",
       "        -0.4983, -0.4998, -0.5535, -0.0686, -0.0380, -0.2017, -0.1002, -0.2665,\n",
       "        -0.3504, -0.4511, -0.1568, -0.1171, -0.6221, -0.1642, -0.1626, -0.4133,\n",
       "        -0.5603, -0.0208, -0.3570, -0.7007, -0.7891, -0.5493, -0.0171, -0.0077,\n",
       "        -0.5379, -0.7172, -0.1710, -0.0589, -0.0392, -0.0019, -0.0553, -0.0094,\n",
       "        -0.0049, -0.0281, -0.0228, -0.0225, -0.0236, -0.0121, -0.4419, -0.0227],\n",
       "       dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5287]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.6465,  0.2000,  0.0500, 25.4749], dtype=torch.float64)  with expected improvement 0.013111424975085247  and expected value of  tensor([[-0.0327]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.06425459407121156]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.1583, -0.1819, -0.4780, -0.5611, -0.7813, -0.5834, -0.4045, -0.5346,\n",
       "        -0.2877, -0.4030, -0.7046, -0.5834, -0.0526, -0.1030, -0.6664, -0.4664,\n",
       "        -0.1452, -0.0189, -0.2396, -0.3237, -0.5722, -0.1366, -0.6209, -0.4299,\n",
       "        -0.3486, -0.5507, -0.1783, -0.4251, -0.1773, -0.3392, -0.6017, -0.2492,\n",
       "        -0.4344, -0.3578, -0.6385, -0.1633, -0.3937, -0.5897, -0.1278, -0.5644,\n",
       "        -0.5706, -0.3854, -0.3795, -0.0708, -0.3240, -0.1419, -0.1327, -0.6086,\n",
       "        -0.6133, -0.7857, -0.3975, -0.6544, -0.4477, -0.6754, -0.2692, -0.6071,\n",
       "        -0.1251, -0.4164, -0.0722, -0.5654, -0.6405, -0.5885, -0.6144, -0.2232,\n",
       "        -0.1019, -0.2605, -0.1263, -0.4422, -0.2409, -0.2048, -0.1195, -0.1865,\n",
       "        -0.4815, -0.4830, -0.5349, -0.0663, -0.0367, -0.1950, -0.0968, -0.2575,\n",
       "        -0.3386, -0.4359, -0.1515, -0.1132, -0.6012, -0.1587, -0.1572, -0.3994,\n",
       "        -0.5414, -0.0201, -0.3450, -0.6771, -0.7625, -0.5309, -0.0165, -0.0088,\n",
       "        -0.5198, -0.6931, -0.1653, -0.0569, -0.0379, -0.0022, -0.0534, -0.0091,\n",
       "        -0.0056, -0.0271, -0.0221, -0.0218, -0.0228, -0.0117, -0.4271, -0.0219],\n",
       "       dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5091]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.6440,  0.2000,  0.0500, 25.4822], dtype=torch.float64)  with expected improvement 0.012791691400439783  and expected value of  tensor([[-0.0332]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.06356479417645937]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.1601, -0.1839, -0.4832, -0.5671, -0.7897, -0.5897, -0.4089, -0.5404,\n",
       "        -0.2909, -0.4073, -0.7122, -0.5897, -0.0532, -0.1041, -0.6737, -0.4714,\n",
       "        -0.1467, -0.0191, -0.2422, -0.3272, -0.5784, -0.1381, -0.6277, -0.4345,\n",
       "        -0.3523, -0.5567, -0.1802, -0.4297, -0.1792, -0.3429, -0.6082, -0.2519,\n",
       "        -0.4391, -0.3617, -0.6454, -0.1650, -0.3980, -0.5961, -0.1292, -0.5706,\n",
       "        -0.5768, -0.3896, -0.3836, -0.0715, -0.3275, -0.1434, -0.1341, -0.6152,\n",
       "        -0.6199, -0.7942, -0.4018, -0.6615, -0.4525, -0.6827, -0.2721, -0.6137,\n",
       "        -0.1265, -0.4209, -0.0730, -0.5716, -0.6475, -0.5948, -0.6211, -0.2257,\n",
       "        -0.1030, -0.2633, -0.1277, -0.4470, -0.2435, -0.2070, -0.1208, -0.1885,\n",
       "        -0.4868, -0.4882, -0.5407, -0.0670, -0.0371, -0.1971, -0.0979, -0.2603,\n",
       "        -0.3423, -0.4407, -0.1531, -0.1144, -0.6077, -0.1605, -0.1589, -0.4038,\n",
       "        -0.5473, -0.0203, -0.3488, -0.6844, -0.7708, -0.5366, -0.0167, -0.0085,\n",
       "        -0.5255, -0.7006, -0.1671, -0.0576, -0.0383, -0.0021, -0.0540, -0.0092,\n",
       "        -0.0054, -0.0274, -0.0223, -0.0220, -0.0231, -0.0119, -0.4317, -0.0222],\n",
       "       dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5152]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.6448,  0.2000,  0.0500, 25.4800], dtype=torch.float64)  with expected improvement 0.012892389401436995  and expected value of  tensor([[-0.0331]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.06378356130222618]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Cannot apply Blossom: odd number of triangles (172719) in surface 1\n",
      "Warning : Cannot apply Blossom: odd number of triangles (202155) in surface 1\n",
      "Warning : ------------------------------\n",
      "Warning : Mesh generation error summary\n",
      "Warning :     1 warning\n",
      "Warning :     0 errors\n",
      "Warning : Check the full log for details\n",
      "Warning : ------------------------------\n",
      "Warning : ------------------------------\n",
      "Warning : Mesh generation error summary\n",
      "Warning :     1 warning\n",
      "Warning :     0 errors\n",
      "Warning : Check the full log for details\n",
      "Warning : ------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective results= [[2.56502, -0.0821634], [2.71321, -0.0310258], [2.4508, -0.0569173], [2.45136, -0.120712], [2.52124, -0.142562], [2.42911, -0.111017]]\n",
      "actual value= tensor(-0.0182, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.0161, dtype=torch.float64)\n",
      "actual value= tensor(-0.0008, dtype=torch.float64)\n",
      "actual improvement= tensor(0.0013, dtype=torch.float64)\n",
      "actual value= tensor(-0.0175, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.0154, dtype=torch.float64)\n",
      "actual value= tensor(-0.0432, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.0411, dtype=torch.float64)\n",
      "actual value= tensor(-0.0266, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.0246, dtype=torch.float64)\n",
      "actual value= tensor(-0.0470, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.0449, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.3477e-01, -1.5309e-01, -3.8359e-01, -4.4822e-01, -6.1961e-01,\n",
       "        -4.6558e-01, -3.2637e-01, -4.2760e-01, -2.3548e-01, -3.2517e-01,\n",
       "        -5.5991e-01, -4.6562e-01, -7.3809e-02, -9.1676e-02, -5.3024e-01,\n",
       "        -3.7452e-01, -1.2452e-01, -2.6243e-02, -1.9799e-01, -2.6348e-01,\n",
       "        -4.5686e-01, -1.1783e-01, -4.9483e-01, -3.4611e-01, -2.8282e-01,\n",
       "        -4.4015e-01, -1.5026e-01, -3.4236e-01, -1.4950e-01, -2.7552e-01,\n",
       "        -4.7987e-01, -2.0545e-01, -3.4966e-01, -2.9000e-01, -5.0849e-01,\n",
       "        -1.3860e-01, -3.1796e-01, -4.7050e-01, -1.1098e-01, -4.5085e-01,\n",
       "        -4.5563e-01, -3.1151e-01, -3.0691e-01, -6.6603e-02, -2.6373e-01,\n",
       "        -1.2197e-01, -1.1477e-01, -4.8522e-01, -4.8885e-01, -6.2306e-01,\n",
       "        -3.2092e-01, -5.2085e-01, -3.5996e-01, -5.3718e-01, -2.2103e-01,\n",
       "        -4.8404e-01, -1.0892e-01, -3.3564e-01, -6.7743e-02, -4.5163e-01,\n",
       "        -5.1007e-01, -4.6955e-01, -4.8976e-01, -1.8528e-01, -9.0830e-02,\n",
       "        -2.1425e-01, -1.0981e-01, -3.5574e-01, -1.9902e-01, -1.7089e-01,\n",
       "        -1.0456e-01, -1.5667e-01, -3.8633e-01, -3.8746e-01, -4.2788e-01,\n",
       "        -6.3133e-02, -4.0115e-02, -1.6327e-01, -8.6886e-02, -2.1198e-01,\n",
       "        -2.7506e-01, -3.5082e-01, -1.2943e-01, -9.9628e-02, -4.7946e-01,\n",
       "        -1.3507e-01, -1.3384e-01, -3.2242e-01, -4.3295e-01, -2.7141e-02,\n",
       "        -2.8007e-01, -5.3855e-01, -6.0504e-01, -4.2471e-01, -2.4434e-02,\n",
       "        -1.5527e-02, -4.1613e-01, -5.5097e-01, -1.4018e-01, -5.5846e-02,\n",
       "        -4.1008e-02, -1.1521e-02, -5.3115e-02, -1.8627e-02, -1.3697e-02,\n",
       "        -3.2629e-02, -2.8705e-02, -2.8480e-02, -2.9274e-02, -2.0660e-02,\n",
       "        -3.4391e-01, -2.8601e-02, -2.4891e-02, -3.3362e-04, -4.4075e-02,\n",
       "        -4.3981e-02, -3.9318e-02, -4.7719e-02], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3964]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.9000,  0.2000,  0.3000, 26.0575], dtype=torch.float64)  with expected improvement 0.004684771003600392  and expected value of  tensor([[-0.0475]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.050181426572796714]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.0680e-01, -1.9145e-01, -2.4927e-01, -6.5366e-01, -2.7866e-01,\n",
       "        -1.7825e-01, -7.0082e-02, -5.9740e-01, -1.0606e-01, -1.9319e-01,\n",
       "        -3.7140e-01, -9.9986e-02, -1.6961e-01, -4.3356e-02, -6.1203e-01,\n",
       "        -1.8249e-01, -1.0205e-01, -1.9498e-02, -1.6894e-01, -6.8322e-02,\n",
       "        -7.8514e-01, -1.5498e-01, -2.5289e-01, -2.7958e-01, -4.1606e-01,\n",
       "        -5.9615e-01, -2.0188e-01, -1.5810e-01, -1.5319e-01, -1.0588e-01,\n",
       "        -7.6575e-01, -1.3857e-01, -4.1632e-01, -6.6681e-02, -2.9420e-01,\n",
       "        -1.0586e-01, -4.2813e-01, -3.5411e-01, -6.9229e-02, -7.8407e-01,\n",
       "        -3.6438e-01, -2.6779e-01, -3.8389e-01, -1.8351e-02, -8.5106e-02,\n",
       "        -1.3394e-01, -1.2884e-01, -1.3425e-01, -5.7345e-01, -2.8668e-01,\n",
       "        -1.6431e-01, -5.7508e-01, -5.3334e-01, -8.6621e-01, -1.2352e-01,\n",
       "        -3.8119e-01, -1.8622e-01, -4.5126e-01, -1.0883e-01, -5.6169e-01,\n",
       "        -1.0953e-01, -8.3700e-01, -7.5231e-01, -1.7554e-01, -8.9939e-02,\n",
       "        -1.2723e-01, -4.2366e-02, -1.3284e-01, -1.6475e-01, -1.3469e-01,\n",
       "        -7.3251e-02, -9.6225e-02, -4.7052e-01, -6.3018e-01, -2.6485e-01,\n",
       "        -3.3295e-02, -2.6113e-02, -1.5594e-01, -1.0090e-01, -2.3133e-01,\n",
       "        -3.1738e-01, -5.0380e-01, -1.1395e-01, -5.7022e-02, -1.2975e-01,\n",
       "        -1.3196e-01, -1.2837e-01, -1.5828e-01, -4.8512e-01, -3.0734e-02,\n",
       "        -2.7765e-01, -1.4995e-01, -1.2992e-01, -1.6469e-01, -5.6149e-02,\n",
       "        -3.5680e-02, -1.5318e-01, -4.6737e-01, -7.9043e-02, -8.0203e-02,\n",
       "        -6.8303e-02, -8.7152e-03, -7.2498e-02, -2.5170e-02, -2.2670e-02,\n",
       "        -1.2057e-02, -3.4390e-02, -6.1156e-03, -6.2862e-03, -3.0042e-02,\n",
       "        -1.0229e-01, -3.0133e-02, -4.1840e-02, -7.6665e-04, -2.1563e-02,\n",
       "        -7.2802e-02, -9.0352e-02, -6.5015e-02], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1476]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.9000,  0.1567,  0.3000, 24.2900], dtype=torch.float64)  with expected improvement 0.009441518465103419  and expected value of  tensor([[-0.0273]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.050070360069519454]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-8.6543e-02, -1.5513e-01, -2.0199e-01, -5.2966e-01, -2.9647e-01,\n",
       "        -2.2277e-01, -1.5616e-01, -4.8407e-01, -1.1267e-01, -1.5654e-01,\n",
       "        -3.0095e-01, -2.2279e-01, -1.3744e-01, -4.3865e-02, -4.9593e-01,\n",
       "        -1.7920e-01, -8.2688e-02, -1.5799e-02, -1.3689e-01, -1.2607e-01,\n",
       "        -6.3620e-01, -1.2558e-01, -2.3676e-01, -2.2654e-01, -3.3713e-01,\n",
       "        -4.8306e-01, -1.6358e-01, -1.6381e-01, -1.2413e-01, -1.3183e-01,\n",
       "        -6.2049e-01, -1.1228e-01, -3.3734e-01, -1.3876e-01, -2.4330e-01,\n",
       "        -8.5775e-02, -3.4691e-01, -2.8693e-01, -5.6096e-02, -6.3532e-01,\n",
       "        -2.9526e-01, -2.1699e-01, -3.1107e-01, -3.1868e-02, -1.2619e-01,\n",
       "        -1.0853e-01, -1.0440e-01, -2.3216e-01, -4.6466e-01, -2.9812e-01,\n",
       "        -1.5355e-01, -4.6598e-01, -4.3217e-01, -7.0188e-01, -1.0576e-01,\n",
       "        -3.0888e-01, -1.5090e-01, -3.6566e-01, -8.8185e-02, -4.5513e-01,\n",
       "        -2.4405e-01, -6.7822e-01, -6.0959e-01, -1.4224e-01, -7.2877e-02,\n",
       "        -1.0309e-01, -5.2542e-02, -1.7021e-01, -1.3349e-01, -1.0914e-01,\n",
       "        -5.9355e-02, -7.7971e-02, -3.8126e-01, -5.1063e-01, -2.1461e-01,\n",
       "        -3.0207e-02, -2.1159e-02, -1.2635e-01, -8.1761e-02, -1.8745e-01,\n",
       "        -2.5717e-01, -4.0823e-01, -9.2331e-02, -4.7669e-02, -2.2941e-01,\n",
       "        -1.0692e-01, -1.0402e-01, -1.5427e-01, -3.9309e-01, -2.4904e-02,\n",
       "        -2.2498e-01, -2.5768e-01, -2.8950e-01, -2.0321e-01, -4.5497e-02,\n",
       "        -2.8912e-02, -1.9911e-01, -3.7871e-01, -6.7071e-02, -6.4988e-02,\n",
       "        -5.5346e-02, -7.0619e-03, -5.8745e-02, -2.0395e-02, -1.8370e-02,\n",
       "        -1.5612e-02, -2.7866e-02, -1.3627e-02, -1.4007e-02, -2.4343e-02,\n",
       "        -1.6455e-01, -2.4417e-02, -3.3903e-02, -6.2122e-04, -2.1089e-02,\n",
       "        -5.8991e-02, -7.3212e-02, -5.2682e-02], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2150]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.9000,  0.1561,  0.3000, 24.6056], dtype=torch.float64)  with expected improvement 0.006710987731063019  and expected value of  tensor([[-0.0336]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.047009734166790614]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.7585e-01, -1.9976e-01, -5.0053e-01, -5.8487e-01, -8.0851e-01,\n",
       "        -6.0752e-01, -4.2587e-01, -5.5796e-01, -3.0727e-01, -4.2431e-01,\n",
       "        -7.3060e-01, -6.0758e-01, -6.8482e-02, -1.1963e-01, -6.9189e-01,\n",
       "        -4.8870e-01, -1.6248e-01, -3.4243e-02, -2.5835e-01, -3.4380e-01,\n",
       "        -5.9614e-01, -1.5375e-01, -6.4568e-01, -4.5162e-01, -3.6904e-01,\n",
       "        -5.7434e-01, -1.9607e-01, -4.4673e-01, -1.9507e-01, -3.5951e-01,\n",
       "        -6.2616e-01, -2.6808e-01, -4.5625e-01, -3.7841e-01, -6.6351e-01,\n",
       "        -1.8085e-01, -4.1489e-01, -6.1394e-01, -1.4481e-01, -5.8829e-01,\n",
       "        -5.9453e-01, -4.0648e-01, -4.0048e-01, -8.6908e-02, -3.4414e-01,\n",
       "        -1.5915e-01, -1.4976e-01, -6.3314e-01, -6.3789e-01, -8.1300e-01,\n",
       "        -4.1875e-01, -6.7964e-01, -4.6970e-01, -7.0094e-01, -2.8841e-01,\n",
       "        -6.3160e-01, -1.4213e-01, -4.3797e-01, -8.8396e-02, -5.8932e-01,\n",
       "        -6.6557e-01, -6.1269e-01, -6.3907e-01, -2.4176e-01, -1.1852e-01,\n",
       "        -2.7956e-01, -1.4329e-01, -4.6419e-01, -2.5969e-01, -2.2299e-01,\n",
       "        -1.3644e-01, -2.0444e-01, -5.0411e-01, -5.0558e-01, -5.5833e-01,\n",
       "        -8.2380e-02, -5.2344e-02, -2.1305e-01, -1.1337e-01, -2.7660e-01,\n",
       "        -3.5892e-01, -4.5778e-01, -1.6889e-01, -1.3000e-01, -6.2563e-01,\n",
       "        -1.7625e-01, -1.7465e-01, -4.2072e-01, -5.6494e-01, -3.5416e-02,\n",
       "        -3.6546e-01, -7.0273e-01, -7.8950e-01, -5.5418e-01, -3.1775e-02,\n",
       "        -1.5379e-02, -5.4299e-01, -7.1895e-01, -1.8291e-01, -7.2872e-02,\n",
       "        -5.3510e-02, -1.5033e-02, -6.9308e-02, -2.4306e-02, -1.7873e-02,\n",
       "        -4.2576e-02, -3.7456e-02, -3.7163e-02, -3.8199e-02, -2.6958e-02,\n",
       "        -4.4876e-01, -3.7320e-02, -3.2479e-02, -1.6550e-04, -5.7513e-02,\n",
       "        -5.7390e-02, -4.2074e-02, -6.2266e-02], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5331]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.9000,  0.2000,  0.3000, 26.5039], dtype=torch.float64)  with expected improvement 0.005510774970993934  and expected value of  tensor([[-0.0535]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.05761257131663245]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.6995e-01, -1.9305e-01, -4.8372e-01, -5.6522e-01, -7.8135e-01,\n",
       "        -5.8711e-01, -4.1156e-01, -5.3922e-01, -2.9694e-01, -4.1005e-01,\n",
       "        -7.0606e-01, -5.8716e-01, -6.6181e-02, -1.1561e-01, -6.6865e-01,\n",
       "        -4.7228e-01, -1.5702e-01, -3.3093e-02, -2.4967e-01, -3.3225e-01,\n",
       "        -5.7611e-01, -1.4858e-01, -6.2399e-01, -4.3645e-01, -3.5664e-01,\n",
       "        -5.5504e-01, -1.8949e-01, -4.3172e-01, -1.8852e-01, -3.4743e-01,\n",
       "        -6.0512e-01, -2.5908e-01, -4.4092e-01, -3.6570e-01, -6.4121e-01,\n",
       "        -1.7478e-01, -4.0095e-01, -5.9331e-01, -1.3994e-01, -5.6853e-01,\n",
       "        -5.7455e-01, -3.9282e-01, -3.8702e-01, -8.3988e-02, -3.3257e-01,\n",
       "        -1.5381e-01, -1.4473e-01, -6.1187e-01, -6.1646e-01, -7.8569e-01,\n",
       "        -4.0469e-01, -6.5680e-01, -4.5392e-01, -6.7739e-01, -2.7872e-01,\n",
       "        -6.1038e-01, -1.3736e-01, -4.2326e-01, -8.5426e-02, -5.6952e-01,\n",
       "        -6.4321e-01, -5.9211e-01, -6.1760e-01, -2.3364e-01, -1.1454e-01,\n",
       "        -2.7017e-01, -1.3847e-01, -4.4860e-01, -2.5097e-01, -2.1550e-01,\n",
       "        -1.3186e-01, -1.9757e-01, -4.8717e-01, -4.8860e-01, -5.3957e-01,\n",
       "        -7.9612e-02, -5.0586e-02, -2.0589e-01, -1.0957e-01, -2.6731e-01,\n",
       "        -3.4686e-01, -4.4240e-01, -1.6321e-01, -1.2563e-01, -6.0461e-01,\n",
       "        -1.7032e-01, -1.6878e-01, -4.0658e-01, -5.4595e-01, -3.4226e-02,\n",
       "        -3.5318e-01, -6.7912e-01, -7.6297e-01, -5.3557e-01, -3.0708e-02,\n",
       "        -1.4862e-02, -5.2474e-01, -6.9479e-01, -1.7677e-01, -7.0424e-02,\n",
       "        -5.1713e-02, -1.4528e-02, -6.6980e-02, -2.3489e-02, -1.7273e-02,\n",
       "        -4.1146e-02, -3.6198e-02, -3.5914e-02, -3.6916e-02, -2.6052e-02,\n",
       "        -4.3368e-01, -3.6066e-02, -3.1388e-02, -1.8968e-04, -5.5580e-02,\n",
       "        -5.5462e-02, -4.0661e-02, -6.0174e-02], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5134]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.9000,  0.2000,  0.3000, 26.4722], dtype=torch.float64)  with expected improvement 0.005453823649818203  and expected value of  tensor([[-0.0526]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.05676341646631727]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.7179e-01, -1.9515e-01, -4.8896e-01, -5.7134e-01, -7.8981e-01,\n",
       "        -5.9347e-01, -4.1602e-01, -5.4506e-01, -3.0016e-01, -4.1449e-01,\n",
       "        -7.1371e-01, -5.9353e-01, -6.6898e-02, -1.1686e-01, -6.7589e-01,\n",
       "        -4.7740e-01, -1.5872e-01, -3.3451e-02, -2.5237e-01, -3.3585e-01,\n",
       "        -5.8235e-01, -1.5019e-01, -6.3075e-01, -4.4118e-01, -3.6050e-01,\n",
       "        -5.6105e-01, -1.9154e-01, -4.3640e-01, -1.9056e-01, -3.5120e-01,\n",
       "        -6.1168e-01, -2.6188e-01, -4.4570e-01, -3.6966e-01, -6.4816e-01,\n",
       "        -1.7667e-01, -4.0529e-01, -5.9974e-01, -1.4146e-01, -5.7469e-01,\n",
       "        -5.8078e-01, -3.9708e-01, -3.9122e-01, -8.4898e-02, -3.3618e-01,\n",
       "        -1.5547e-01, -1.4630e-01, -6.1850e-01, -6.2314e-01, -7.9420e-01,\n",
       "        -4.0907e-01, -6.6392e-01, -4.5884e-01, -6.8473e-01, -2.8174e-01,\n",
       "        -6.1700e-01, -1.3884e-01, -4.2784e-01, -8.6351e-02, -5.7569e-01,\n",
       "        -6.5018e-01, -5.9853e-01, -6.2429e-01, -2.3617e-01, -1.1578e-01,\n",
       "        -2.7310e-01, -1.3998e-01, -4.5346e-01, -2.5369e-01, -2.1784e-01,\n",
       "        -1.3329e-01, -1.9971e-01, -4.9245e-01, -4.9389e-01, -5.4542e-01,\n",
       "        -8.0474e-02, -5.1134e-02, -2.0812e-01, -1.1075e-01, -2.7020e-01,\n",
       "        -3.5062e-01, -4.4719e-01, -1.6498e-01, -1.2699e-01, -6.1116e-01,\n",
       "        -1.7217e-01, -1.7061e-01, -4.1099e-01, -5.5187e-01, -3.4597e-02,\n",
       "        -3.5700e-01, -6.8648e-01, -7.7124e-01, -5.4137e-01, -3.1040e-02,\n",
       "        -1.5024e-02, -5.3043e-01, -7.0232e-01, -1.7868e-01, -7.1187e-02,\n",
       "        -5.2273e-02, -1.4685e-02, -6.7705e-02, -2.3744e-02, -1.7460e-02,\n",
       "        -4.1591e-02, -3.6590e-02, -3.6303e-02, -3.7316e-02, -2.6335e-02,\n",
       "        -4.3838e-01, -3.6457e-02, -3.1728e-02, -1.8215e-04, -5.6182e-02,\n",
       "        -5.6063e-02, -4.1101e-02, -6.0826e-02], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5195]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.9000,  0.2000,  0.3000, 26.4823], dtype=torch.float64)  with expected improvement 0.005471512714542119  and expected value of  tensor([[-0.0529]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.05702874856875254]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "/opt/OpenFOAM/OpenFOAM-10/bin/tools/RunFunctions: line 53: 202953 Floating point exception(core dumped) $APP_RUN \"$@\" > log.$LOG_SUFFIX 2>&1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective results= [[2.73608, -0.0191017], [-2.0, 2.0], [2.57854, -0.0484572], [2.74069, -0.0151173], [2.74038, -0.0153727], [2.74127, -0.0156259]]\n",
      "actual value= tensor(0.0038, dtype=torch.float64)\n",
      "actual improvement= tensor(0.0040, dtype=torch.float64)\n",
      "actual value= tensor(-0.1700, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.1698, dtype=torch.float64)\n",
      "actual value= tensor(-0.0120, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.0118, dtype=torch.float64)\n",
      "actual value= tensor(0.0026, dtype=torch.float64)\n",
      "actual improvement= tensor(0.0028, dtype=torch.float64)\n",
      "actual value= tensor(0.0029, dtype=torch.float64)\n",
      "actual improvement= tensor(0.0031, dtype=torch.float64)\n",
      "actual value= tensor(0.0028, dtype=torch.float64)\n",
      "actual improvement= tensor(0.0029, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.2623, -0.2751, -0.3038, -0.3544, -0.4885, -0.3679, -0.2590, -0.3382,\n",
       "        -0.2622, -0.2753, -0.4417, -0.3680, -0.2718, -0.2527, -0.4185, -0.2967,\n",
       "        -0.2616, -0.2491, -0.2717, -0.2565, -0.3647, -0.2696, -0.3908, -0.2884,\n",
       "        -0.3090, -0.3481, -0.2766, -0.2715, -0.2693, -0.2622, -0.3791, -0.2671,\n",
       "        -0.3090, -0.2562, -0.4015, -0.2622, -0.3108, -0.3718, -0.2566, -0.3645,\n",
       "        -0.3602, -0.2866, -0.3041, -0.2489, -0.2590, -0.2664, -0.2656, -0.3833,\n",
       "        -0.3862, -0.4912, -0.2710, -0.4112, -0.3267, -0.4240, -0.2648, -0.3824,\n",
       "        -0.2743, -0.3143, -0.2626, -0.3570, -0.4028, -0.3725, -0.3869, -0.2727,\n",
       "        -0.2597, -0.2654, -0.2526, -0.2820, -0.2710, -0.2665, -0.2572, -0.2607,\n",
       "        -0.3172, -0.3413, -0.3385, -0.2512, -0.2501, -0.2697, -0.2614, -0.2811,\n",
       "        -0.2941, -0.3222, -0.2634, -0.2548, -0.3788, -0.2661, -0.2655, -0.2701,\n",
       "        -0.3424, -0.2508, -0.2881, -0.4250, -0.4771, -0.3360, -0.2546, -0.2516,\n",
       "        -0.3293, -0.4348, -0.2581, -0.2583, -0.2565, -0.2475, -0.2571, -0.2500,\n",
       "        -0.2496, -0.2480, -0.2514, -0.2469, -0.2462, -0.2507, -0.2728, -0.2507,\n",
       "        -0.2525, -0.2463, -0.2494, -0.2572, -0.2598, -0.2560, -0.2448, -0.6231,\n",
       "        -0.2484, -0.2444, -0.2444, -0.2444], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3026]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.7034,  0.2000,  0.2293, 25.2269], dtype=torch.float64)  with expected improvement 5.135598019335031e-05  and expected value of  tensor([[-0.2932]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.02015103629890699]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.6027, -0.6321, -0.6522, -0.7925, -0.6624, -0.6275, -0.5896, -0.7730,\n",
       "        -0.6025, -0.6327, -0.6945, -0.5821, -0.6245, -0.5807, -0.7780, -0.6290,\n",
       "        -0.6011, -0.5725, -0.6243, -0.5894, -0.8381, -0.6195, -0.6534, -0.6627,\n",
       "        -0.7100, -0.7725, -0.6357, -0.6205, -0.6188, -0.6024, -0.8314, -0.6138,\n",
       "        -0.7101, -0.5888, -0.6678, -0.6024, -0.7142, -0.6885, -0.5897, -0.8377,\n",
       "        -0.6921, -0.6586, -0.6989, -0.5721, -0.5952, -0.6122, -0.6104, -0.6123,\n",
       "        -0.7646, -0.6652, -0.6227, -0.7652, -0.7507, -0.8662, -0.6085, -0.6979,\n",
       "        -0.6303, -0.7222, -0.6034, -0.7606, -0.6000, -0.8561, -0.8267, -0.6266,\n",
       "        -0.5969, -0.6098, -0.5804, -0.6118, -0.6228, -0.6124, -0.5911, -0.5991,\n",
       "        -0.7289, -0.7843, -0.6576, -0.5772, -0.5748, -0.6198, -0.6007, -0.6459,\n",
       "        -0.6758, -0.7405, -0.6052, -0.5855, -0.6107, -0.6115, -0.6102, -0.6206,\n",
       "        -0.7340, -0.5764, -0.6620, -0.6177, -0.5983, -0.6228, -0.5852, -0.5781,\n",
       "        -0.6188, -0.7278, -0.5931, -0.5935, -0.5894, -0.5687, -0.5908, -0.5744,\n",
       "        -0.5736, -0.5699, -0.5776, -0.5674, -0.5657, -0.5761, -0.6012, -0.5761,\n",
       "        -0.5802, -0.5660, -0.5732, -0.5909, -0.5970, -0.5882, -0.5626, -0.1338,\n",
       "        -0.5708, -0.5615, -0.5616, -0.5617], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6373]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.2693,  0.1184,  0.2123, 34.6411], dtype=torch.float64)  with expected improvement 8.465549036604644e-29  and expected value of  tensor([[-0.6486]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.0467436617329464]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.4884, -0.5122, -0.5285, -0.6421, -0.5367, -0.5085, -0.4777, -0.6263,\n",
       "        -0.4882, -0.5127, -0.5628, -0.4717, -0.5061, -0.4706, -0.6304, -0.5097,\n",
       "        -0.4871, -0.4639, -0.5059, -0.4776, -0.6791, -0.5019, -0.5295, -0.5370,\n",
       "        -0.5753, -0.6260, -0.5151, -0.5028, -0.5014, -0.4881, -0.6736, -0.4973,\n",
       "        -0.5754, -0.4771, -0.5411, -0.4881, -0.5787, -0.5579, -0.4778, -0.6788,\n",
       "        -0.5608, -0.5337, -0.5663, -0.4635, -0.4823, -0.4960, -0.4946, -0.4961,\n",
       "        -0.6196, -0.5390, -0.5046, -0.6200, -0.6083, -0.7019, -0.4931, -0.5655,\n",
       "        -0.5107, -0.5852, -0.4890, -0.6163, -0.4862, -0.6937, -0.6699, -0.5077,\n",
       "        -0.4837, -0.4941, -0.4703, -0.4957, -0.5047, -0.4962, -0.4790, -0.4854,\n",
       "        -0.5907, -0.6355, -0.5328, -0.4677, -0.4657, -0.5022, -0.4867, -0.5234,\n",
       "        -0.5476, -0.6000, -0.4904, -0.4744, -0.4949, -0.4955, -0.4945, -0.5029,\n",
       "        -0.5948, -0.4670, -0.5364, -0.5005, -0.4848, -0.5047, -0.4742, -0.4684,\n",
       "        -0.5014, -0.5898, -0.4806, -0.4809, -0.4776, -0.4608, -0.4788, -0.4655,\n",
       "        -0.4648, -0.4618, -0.4680, -0.4598, -0.4584, -0.4668, -0.4871, -0.4668,\n",
       "        -0.4701, -0.4586, -0.4644, -0.4788, -0.4838, -0.4767, -0.4559, -0.2981,\n",
       "        -0.4625, -0.4550, -0.4551, -0.4551], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5173]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.9000,  0.1567,  0.3000, 24.2900], dtype=torch.float64)  with expected improvement 1.2377292672351469e-27  and expected value of  tensor([[-0.5062]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.019471292127857403]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.1424, -0.1611, -0.3964, -0.4624, -0.6374, -0.4801, -0.3380, -0.4413,\n",
       "        -0.2452, -0.3368, -0.5764, -0.4802, -0.1348, -0.1254, -0.5461, -0.3872,\n",
       "        -0.1319, -0.1236, -0.2069, -0.2738, -0.4712, -0.1337, -0.5100, -0.3582,\n",
       "        -0.2935, -0.4542, -0.1582, -0.3543, -0.1574, -0.2861, -0.4947, -0.2146,\n",
       "        -0.3618, -0.3009, -0.5239, -0.1463, -0.3294, -0.4851, -0.1273, -0.4651,\n",
       "        -0.4700, -0.3228, -0.3181, -0.1235, -0.2741, -0.1322, -0.1318, -0.5002,\n",
       "        -0.5039, -0.6409, -0.3324, -0.5365, -0.3723, -0.5532, -0.2305, -0.4990,\n",
       "        -0.1361, -0.3475, -0.1303, -0.4659, -0.5255, -0.4842, -0.5048, -0.1940,\n",
       "        -0.1289, -0.2235, -0.1253, -0.3680, -0.2080, -0.1793, -0.1276, -0.1648,\n",
       "        -0.3992, -0.4004, -0.4416, -0.1246, -0.1241, -0.1715, -0.1297, -0.2212,\n",
       "        -0.2856, -0.3630, -0.1369, -0.1264, -0.4943, -0.1427, -0.1415, -0.3340,\n",
       "        -0.4468, -0.1244, -0.2907, -0.5546, -0.6225, -0.4384, -0.1263, -0.1248,\n",
       "        -0.4296, -0.5673, -0.1479, -0.1281, -0.1272, -0.1228, -0.1276, -0.1240,\n",
       "        -0.1238, -0.1230, -0.1247, -0.1225, -0.1221, -0.1244, -0.3559, -0.1244,\n",
       "        -0.1253, -0.1222, -0.1237, -0.1276, -0.1289, -0.1270, -0.1215, -0.8130,\n",
       "        -0.1232, -0.1212, -0.1212, -0.1213], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4073]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.3746,  0.1854,  0.1492, 27.0483], dtype=torch.float64)  with expected improvement 0.02585883877810832  and expected value of  tensor([[-0.1125]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.05312205939360334]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.1491, -0.1564, -0.3831, -0.4469, -0.6160, -0.4640, -0.3266, -0.4265,\n",
       "        -0.2370, -0.3255, -0.5571, -0.4640, -0.1545, -0.1437, -0.5278, -0.3742,\n",
       "        -0.1487, -0.1416, -0.2000, -0.2646, -0.4554, -0.1533, -0.4928, -0.3461,\n",
       "        -0.2837, -0.4389, -0.1573, -0.3424, -0.1531, -0.2765, -0.4781, -0.2073,\n",
       "        -0.3496, -0.2908, -0.5063, -0.1490, -0.3183, -0.4688, -0.1459, -0.4495,\n",
       "        -0.4542, -0.3120, -0.3074, -0.1415, -0.2648, -0.1515, -0.1510, -0.4834,\n",
       "        -0.4870, -0.6194, -0.3213, -0.5185, -0.3598, -0.5346, -0.2227, -0.4822,\n",
       "        -0.1559, -0.3358, -0.1493, -0.4502, -0.5079, -0.4679, -0.4878, -0.1874,\n",
       "        -0.1477, -0.2160, -0.1436, -0.3556, -0.2010, -0.1733, -0.1462, -0.1592,\n",
       "        -0.3858, -0.3869, -0.4268, -0.1428, -0.1422, -0.1657, -0.1486, -0.2138,\n",
       "        -0.2760, -0.3508, -0.1497, -0.1449, -0.4777, -0.1513, -0.1510, -0.3228,\n",
       "        -0.4318, -0.1426, -0.2810, -0.5360, -0.6016, -0.4237, -0.1448, -0.1430,\n",
       "        -0.4152, -0.5482, -0.1467, -0.1468, -0.1458, -0.1407, -0.1462, -0.1421,\n",
       "        -0.1419, -0.1410, -0.1429, -0.1404, -0.1400, -0.1425, -0.3440, -0.1425,\n",
       "        -0.1436, -0.1400, -0.1418, -0.1462, -0.1477, -0.1455, -0.1392, -0.7857,\n",
       "        -0.1412, -0.1389, -0.1389, -0.1390], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3909]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.3580,  0.1696,  0.1461, 27.1375], dtype=torch.float64)  with expected improvement 0.024399934472379002  and expected value of  tensor([[-0.1324]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.05259468822100087]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.1432, -0.1574, -0.3872, -0.4517, -0.6226, -0.4690, -0.3302, -0.4311,\n",
       "        -0.2395, -0.3290, -0.5631, -0.4691, -0.1484, -0.1380, -0.5335, -0.3782,\n",
       "        -0.1428, -0.1360, -0.2022, -0.2675, -0.4603, -0.1472, -0.4982, -0.3499,\n",
       "        -0.2868, -0.4437, -0.1546, -0.3461, -0.1538, -0.2795, -0.4833, -0.2096,\n",
       "        -0.3534, -0.2939, -0.5118, -0.1431, -0.3218, -0.4739, -0.1401, -0.4543,\n",
       "        -0.4591, -0.3154, -0.3108, -0.1359, -0.2677, -0.1454, -0.1450, -0.4886,\n",
       "        -0.4922, -0.6261, -0.3247, -0.5241, -0.3637, -0.5404, -0.2251, -0.4874,\n",
       "        -0.1497, -0.3394, -0.1434, -0.4551, -0.5134, -0.4730, -0.4931, -0.1895,\n",
       "        -0.1418, -0.2184, -0.1379, -0.3595, -0.2032, -0.1751, -0.1404, -0.1609,\n",
       "        -0.3900, -0.3911, -0.4314, -0.1371, -0.1366, -0.1675, -0.1427, -0.2161,\n",
       "        -0.2790, -0.3546, -0.1438, -0.1391, -0.4829, -0.1453, -0.1450, -0.3262,\n",
       "        -0.4365, -0.1369, -0.2840, -0.5418, -0.6081, -0.4283, -0.1390, -0.1373,\n",
       "        -0.4197, -0.5542, -0.1445, -0.1410, -0.1400, -0.1351, -0.1404, -0.1365,\n",
       "        -0.1363, -0.1354, -0.1372, -0.1348, -0.1344, -0.1369, -0.3477, -0.1369,\n",
       "        -0.1378, -0.1345, -0.1362, -0.1404, -0.1418, -0.1398, -0.1337, -0.7942,\n",
       "        -0.1356, -0.1334, -0.1334, -0.1334], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3960]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "new candidate= tensor([ 0.3581,  0.1723,  0.1447, 27.1117], dtype=torch.float64)  with expected improvement 0.025245485424566318  and expected value of  tensor([[-0.1256]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>) +- [[0.05298234238706883]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective results= [[2.70009, -0.0222817], [1.98704, -0.19683], [-2.0, 2.0], [2.56035, -0.0481475], [2.5131, -0.0499298], [2.51864, -0.050879]]\n",
      "actual value= tensor(-0.2452, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.1118, dtype=torch.float64)\n",
      "actual value= tensor(-0.6122, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.4788, dtype=torch.float64)\n",
      "actual value= tensor(-0.2981, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.1647, dtype=torch.float64)\n",
      "actual value= tensor(-0.1232, dtype=torch.float64)\n",
      "actual improvement= tensor(0.0102, dtype=torch.float64)\n",
      "actual value= tensor(-0.1413, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.0079, dtype=torch.float64)\n",
      "actual value= tensor(-0.1358, dtype=torch.float64)\n",
      "actual improvement= tensor(-0.0024, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objective values</th>\n",
       "      <th>expected improvements</th>\n",
       "      <th>actual improvements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.029785825209035888, -0.017508119771386273,...</td>\n",
       "      <td>[0.008460668062768536, 0.009088071671658537, 0...</td>\n",
       "      <td>[-0.025579439161222503, -0.017508119771386273,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5.808345446379581e-05, -0.003710354077630441,...</td>\n",
       "      <td>[0.015060063199863841, 0.013503145528086548, 0...</td>\n",
       "      <td>[0.004264469502277182, -0.003710354077630441, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.044824856587746265, -0.008654749199180927,...</td>\n",
       "      <td>[0.011730287213705035, 0.010693667890363714, 0...</td>\n",
       "      <td>[-0.04061847053993288, -0.008654749199180927, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.009098937441501, -0.012149704752200187, -0...</td>\n",
       "      <td>[0.010702716998562118, 0.01103168050078431, 0....</td>\n",
       "      <td>[-0.004892551393687614, -0.012149704752200187,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.002456835312778461, -0.42705291661569195, ...</td>\n",
       "      <td>[0.01042507717858326, 0.010813442522512075, 0....</td>\n",
       "      <td>[0.0017495507350349252, -0.42705291661569195, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-0.027080130391238733, -0.02218216299945567, ...</td>\n",
       "      <td>[0.010512100239645387, 0.010882298738215439, 0...</td>\n",
       "      <td>[-0.022873744343425345, -0.02218216299945567, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    objective values  \\\n",
       "0  [-0.029785825209035888, -0.017508119771386273,...   \n",
       "1  [5.808345446379581e-05, -0.003710354077630441,...   \n",
       "2  [-0.044824856587746265, -0.008654749199180927,...   \n",
       "3  [-0.009098937441501, -0.012149704752200187, -0...   \n",
       "4  [-0.002456835312778461, -0.42705291661569195, ...   \n",
       "5  [-0.027080130391238733, -0.02218216299945567, ...   \n",
       "\n",
       "                               expected improvements  \\\n",
       "0  [0.008460668062768536, 0.009088071671658537, 0...   \n",
       "1  [0.015060063199863841, 0.013503145528086548, 0...   \n",
       "2  [0.011730287213705035, 0.010693667890363714, 0...   \n",
       "3  [0.010702716998562118, 0.01103168050078431, 0....   \n",
       "4  [0.01042507717858326, 0.010813442522512075, 0....   \n",
       "5  [0.010512100239645387, 0.010882298738215439, 0...   \n",
       "\n",
       "                                 actual improvements  \n",
       "0  [-0.025579439161222503, -0.017508119771386273,...  \n",
       "1  [0.004264469502277182, -0.003710354077630441, ...  \n",
       "2  [-0.04061847053993288, -0.008654749199180927, ...  \n",
       "3  [-0.004892551393687614, -0.012149704752200187,...  \n",
       "4  [0.0017495507350349252, -0.42705291661569195, ...  \n",
       "5  [-0.022873744343425345, -0.02218216299945567, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from botorch.utils.multi_objective.scalarization import get_chebyshev_scalarization\n",
    "from botorch.acquisition.objective import GenericMCObjective\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.utils.sampling import sample_simplex\n",
    "from torch import Tensor\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.utils.transforms import normalize\n",
    "\n",
    "weights=sample_simplex(2,6)\n",
    "#weights=torch.tensor([[1,0],[0,1]],dtype=dtype)\n",
    "NUM_WEIGHTS=weights.shape[0]\n",
    "bounds = torch.stack([torch.tensor(x_lims)[:,0], torch.tensor(x_lims)[:,1]])\n",
    "print(\"weights=\",weights)\n",
    "\n",
    "def get_chebyshev_scalarization(\n",
    "    weights: Tensor, Y: Tensor, alpha: float = 0.05\n",
    "):\n",
    "    def chebyshev_obj(Y: Tensor) -> Tensor:\n",
    "        product = weights * Y\n",
    "        return product.min(dim=-1).values + alpha * product.sum(dim=-1)\n",
    "    Y_bounds = torch.stack([Y.min(dim=-2).values, Y.max(dim=-2).values])\n",
    "    def obj(Y: Tensor) -> Tensor:\n",
    "        # scale to [0,1]\n",
    "        Y_normalized = normalize(Y, bounds=Y_bounds)-1\n",
    "        return chebyshev_obj(Y=Y_normalized)\n",
    "\n",
    "    return obj\n",
    "\n",
    "import pandas as pd\n",
    "expected_improvements=[[] for _ in range(NUM_WEIGHTS)]\n",
    "actual_improvements=[[] for _ in range(NUM_WEIGHTS)]\n",
    "scalarized_values=[[] for _ in range(NUM_WEIGHTS)]\n",
    "variances=[[] for _ in range(NUM_WEIGHTS)]\n",
    "NUM_ITERATIONS=5\n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "    evaluation_promises=[]\n",
    "    new_X=[]\n",
    "    scalarizations=[]\n",
    "    for i in range(NUM_WEIGHTS):\n",
    "        scalarization=get_chebyshev_scalarization(weights[i,:],train_Y,alpha=0)\n",
    "        scalarizations.append(scalarization)\n",
    "        acquisition_values=scalarization(train_Y)\n",
    "        display(acquisition_values)\n",
    "        model=get_fitted_model(train_X,acquisition_values.unsqueeze(1))\n",
    "        prediction=model.posterior(torch.tensor([[0.4,0.0,0.15,0.0]]))\n",
    "        print(prediction.mean)\n",
    "        acquisition_function=ExpectedImprovement(model,acquisition_values.max())\n",
    "        candidate, acq_value = optimize_acqf(\n",
    "            acquisition_function, bounds=bounds, q=1, num_restarts=1, batch_initial_conditions=train_X\n",
    "        )\n",
    "        expected_improvements[i].append(acq_value.tolist())\n",
    "        expected_value=model.posterior(candidate.unsqueeze(0))\n",
    "        print(\"new candidate=\",candidate,\" with expected improvement\",acq_value.tolist(),\" and expected value of \",expected_value.mean,\"+-\",torch.sqrt(expected_value.variance).tolist())\n",
    "        new_X.append(candidate)\n",
    "        variances.append(expected_value.variance.tolist())\n",
    "        evaluation_promises.append(evaluate_profile(candidate.tolist()))\n",
    "    #print(\"promises: \",evaluation_promises)\n",
    "    results=await asyncio.gather(*evaluation_promises)\n",
    "    print(\"objective results=\",results)\n",
    "    for i in range(NUM_WEIGHTS):\n",
    "        actual_value=scalarizations[i](torch.tensor(results[i]))\n",
    "        print(\"actual value=\",actual_value)\n",
    "        acquisition_values=scalarization(train_Y)\n",
    "        actual_improvement=actual_value-acquisition_values.max()\n",
    "        print(\"actual improvement=\",actual_improvement)\n",
    "        actual_improvements[i].append(actual_improvement.tolist())\n",
    "        scalarized_values[i].append(actual_value.tolist())\n",
    "    train_X = torch.cat([train_X, torch.stack(new_X)])\n",
    "    train_Y = torch.cat([train_Y, torch.tensor(results)])\n",
    "\n",
    "df=pd.DataFrame({\n",
    "    'objective values':scalarized_values,\n",
    "    'expected improvements': expected_improvements,\n",
    "    'actual improvements':actual_improvements\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w= [0.6230558156967163, 0.3769441843032837]\n",
      "\\begin{tabular}{rrrr}\n",
      "\\toprule\n",
      " Iteration &  Objective value &  Expected improvements &  Actual improvements \\\\\n",
      "\\midrule\n",
      "         1 &        -0.029786 &               0.008461 &            -0.025579 \\\\\n",
      "         2 &        -0.017508 &               0.009088 &            -0.017508 \\\\\n",
      "         3 &        -0.018207 &               0.009890 &            -0.016137 \\\\\n",
      "         4 &         0.003834 &               0.004685 &             0.004016 \\\\\n",
      "         5 &        -0.245225 &               0.000051 &            -0.111815 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "w= [0.13379138708114624, 0.8662086129188538]\n",
      "\\begin{tabular}{rrrr}\n",
      "\\toprule\n",
      " Iteration &  Objective value &  Expected improvements &  Actual improvements \\\\\n",
      "\\midrule\n",
      "         1 &         0.000058 &           1.506006e-02 &             0.004264 \\\\\n",
      "         2 &        -0.003710 &           1.350315e-02 &            -0.003710 \\\\\n",
      "         3 &        -0.000767 &           1.043310e-02 &             0.001304 \\\\\n",
      "         4 &        -0.169994 &           9.441518e-03 &            -0.169812 \\\\\n",
      "         5 &        -0.612160 &           8.465549e-29 &            -0.478750 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "w= [0.298115611076355, 0.701884388923645]\n",
      "\\begin{tabular}{rrrr}\n",
      "\\toprule\n",
      " Iteration &  Objective value &  Expected improvements &  Actual improvements \\\\\n",
      "\\midrule\n",
      "         1 &        -0.044825 &           1.173029e-02 &            -0.040618 \\\\\n",
      "         2 &        -0.008655 &           1.069367e-02 &            -0.008655 \\\\\n",
      "         3 &        -0.017472 &           9.765024e-03 &            -0.015402 \\\\\n",
      "         4 &        -0.011966 &           6.710988e-03 &            -0.011784 \\\\\n",
      "         5 &        -0.298116 &           1.237729e-27 &            -0.164705 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "w= [0.8130035400390625, 0.1869964599609375]\n",
      "\\begin{tabular}{rrrr}\n",
      "\\toprule\n",
      " Iteration &  Objective value &  Expected improvements &  Actual improvements \\\\\n",
      "\\midrule\n",
      "         1 &        -0.009099 &               0.010703 &            -0.004893 \\\\\n",
      "         2 &        -0.012150 &               0.011032 &            -0.012150 \\\\\n",
      "         3 &        -0.043155 &               0.013111 &            -0.041084 \\\\\n",
      "         4 &         0.002593 &               0.005511 &             0.002775 \\\\\n",
      "         5 &        -0.123209 &               0.025859 &             0.010202 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "w= [0.7856877446174622, 0.21431225538253784]\n",
      "\\begin{tabular}{rrrr}\n",
      "\\toprule\n",
      " Iteration &  Objective value &  Expected improvements &  Actual improvements \\\\\n",
      "\\midrule\n",
      "         1 &        -0.002457 &               0.010425 &             0.001750 \\\\\n",
      "         2 &        -0.427053 &               0.010813 &            -0.427053 \\\\\n",
      "         3 &        -0.026625 &               0.012792 &            -0.024554 \\\\\n",
      "         4 &         0.002921 &               0.005454 &             0.003103 \\\\\n",
      "         5 &        -0.141329 &               0.024400 &            -0.007919 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "w= [0.7942014932632446, 0.20579850673675537]\n",
      "\\begin{tabular}{rrrr}\n",
      "\\toprule\n",
      " Iteration &  Objective value &  Expected improvements &  Actual improvements \\\\\n",
      "\\midrule\n",
      "         1 &        -0.027080 &               0.010512 &            -0.022874 \\\\\n",
      "         2 &        -0.022182 &               0.010882 &            -0.022182 \\\\\n",
      "         3 &        -0.047010 &               0.012892 &            -0.044940 \\\\\n",
      "         4 &         0.002757 &               0.005472 &             0.002939 \\\\\n",
      "         5 &        -0.135778 &               0.025245 &            -0.002368 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173376/3830280330.py:9: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(table.to_latex(index=False))\n"
     ]
    }
   ],
   "source": [
    "for i in range(NUM_WEIGHTS):\n",
    "    print(\"w=\",weights[i].tolist())\n",
    "    table=pd.DataFrame({\n",
    "        'Iteration': range(1,NUM_ITERATIONS+1),\n",
    "        'Objective value':scalarized_values[i],\n",
    "        'Expected improvements': expected_improvements[i],\n",
    "        'Actual improvements':actual_improvements[i]\n",
    "    })\n",
    "    print(table.to_latex(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3739e-01,  7.9306e-02,  1.0256e-01,  2.5103e+01],\n",
       "        [ 2.7886e-01,  1.8191e-01,  2.8754e-01,  1.3561e+01],\n",
       "        [ 1.0387e-01, -4.8587e-02,  2.2228e-01,  1.3167e+01],\n",
       "        [ 4.5826e-01, -1.4955e-01,  1.5524e-01,  2.6218e+01],\n",
       "        [ 6.9568e-01, -1.6911e-01,  2.5780e-01,  3.5831e+00],\n",
       "        [ 6.1592e-01, -6.9133e-02,  1.3380e-01,  7.9757e+00],\n",
       "        [ 1.4825e-01,  2.7022e-02,  1.0109e-01,  6.5286e+00],\n",
       "        [ 2.0521e-01, -1.1956e-01,  1.8094e-01,  2.5450e+01],\n",
       "        [ 1.6375e-01,  1.1698e-01,  6.6139e-02,  6.5688e+00],\n",
       "        [ 1.6249e-01,  1.3232e-01,  2.7471e-01,  1.6463e-01],\n",
       "        [ 4.5287e-01, -1.6824e-01,  2.5655e-01,  7.4871e+00],\n",
       "        [ 2.3305e-01, -3.3914e-02,  7.7110e-02,  2.5258e+00],\n",
       "        [ 8.6719e-01,  1.5894e-01,  1.0855e-01,  2.7853e+01],\n",
       "        [ 4.2076e-01,  1.1872e-01,  1.0441e-01,  1.7589e+01],\n",
       "        [ 4.1593e-01, -1.6095e-01,  2.8181e-01,  1.6926e+01],\n",
       "        [ 6.6980e-01, -2.2145e-02,  2.4722e-01,  9.9564e+00],\n",
       "        [ 8.9952e-01,  6.4930e-02,  1.0033e-01,  1.9243e+01],\n",
       "        [ 4.0627e-01,  1.8807e-01,  1.8981e-01,  2.9996e+01],\n",
       "        [ 6.9433e-01,  2.5918e-02,  2.4618e-01,  2.6906e+01],\n",
       "        [ 7.5052e-01,  7.4836e-02,  1.2825e-01,  3.0318e+00],\n",
       "        [ 7.3614e-01, -1.7634e-01,  7.4904e-02,  3.1845e+01],\n",
       "        [ 3.2282e-01,  1.8458e-01,  2.5453e-01,  1.4915e+01],\n",
       "        [ 5.8279e-01, -9.5630e-02,  2.3217e-01,  8.1742e+00],\n",
       "        [ 7.3067e-01, -3.8997e-02,  2.7854e-01,  1.7882e+01],\n",
       "        [ 3.8465e-01, -1.8769e-02,  7.7450e-02,  2.9471e+01],\n",
       "        [ 5.6060e-01, -1.1954e-01,  2.0590e-01,  2.5623e+01],\n",
       "        [ 6.7883e-01,  8.7365e-02,  1.0580e-01,  2.8663e+01],\n",
       "        [ 6.2255e-01,  2.0079e-02,  2.9891e-01,  7.4990e+00],\n",
       "        [ 3.0640e-01,  7.8970e-02,  1.4058e-01,  3.0351e+01],\n",
       "        [ 1.6034e-01,  4.2301e-02,  1.7333e-01,  9.6864e+00],\n",
       "        [ 4.0451e-01, -1.6033e-01,  2.5303e-01,  2.8690e+01],\n",
       "        [ 2.8354e-01,  4.0564e-02,  2.7812e-01,  2.0166e+01],\n",
       "        [ 7.4762e-01, -5.4062e-02,  1.6042e-01,  2.6191e+01],\n",
       "        [ 2.2784e-01,  8.4054e-02,  9.4323e-02,  3.9712e+00],\n",
       "        [ 1.1360e-01, -1.8849e-01,  1.1644e-01,  4.5829e+00],\n",
       "        [ 4.7410e-01,  7.2250e-02,  1.4971e-01,  2.6659e+01],\n",
       "        [ 6.5349e-01, -3.7167e-02,  1.7760e-01,  3.0160e+01],\n",
       "        [ 7.8733e-01, -1.1406e-01,  2.9177e-01,  1.1984e+01],\n",
       "        [ 6.6378e-01,  1.2302e-01,  1.5986e-01,  1.3123e+01],\n",
       "        [ 7.1927e-01, -1.4612e-01,  1.9343e-01,  3.4736e+01],\n",
       "        [ 7.6800e-01, -1.1869e-01,  2.9577e-01,  1.2769e+01],\n",
       "        [ 6.5155e-01, -3.1770e-02,  2.6572e-01,  2.0702e+01],\n",
       "        [ 8.8753e-01, -2.6898e-02,  2.6217e-01,  3.0954e+01],\n",
       "        [ 5.8285e-01,  1.2984e-01,  2.2198e-01,  2.1370e+01],\n",
       "        [ 4.8197e-01,  1.2346e-01,  9.6808e-02,  1.0941e+00],\n",
       "        [ 2.6930e-01,  1.1843e-01,  2.1226e-01,  3.4641e+01],\n",
       "        [ 4.1417e-01,  1.7426e-01,  1.6276e-01,  1.0496e+01],\n",
       "        [ 3.5731e-01, -7.3380e-02,  9.6676e-02,  5.3306e+00],\n",
       "        [ 3.8348e-01, -1.4896e-01,  1.9878e-01,  1.8851e+01],\n",
       "        [ 5.4474e-01, -1.8239e-01,  2.0410e-01,  4.0214e+00],\n",
       "        [ 1.3236e-01,  1.3016e-01,  1.9356e-01,  2.4751e-01],\n",
       "        [ 3.8250e-01, -1.6464e-01,  2.1305e-01,  1.6263e+01],\n",
       "        [ 8.7843e-01, -1.9665e-01,  2.7409e-01,  2.0947e+01],\n",
       "        [ 7.7716e-01, -1.9350e-01,  2.9877e-01,  2.7218e+01],\n",
       "        [ 6.1835e-01,  2.0245e-02,  1.4874e-01,  1.7709e+01],\n",
       "        [ 3.7237e-01, -1.1616e-01,  2.8666e-01,  1.1833e+01],\n",
       "        [ 1.6532e-01,  1.8068e-01,  1.7402e-01,  3.0114e+01],\n",
       "        [ 3.8906e-01, -4.9762e-02,  1.8036e-01,  2.8712e+01],\n",
       "        [ 2.6532e-01,  1.9051e-01,  1.2782e-01,  2.0101e+01],\n",
       "        [ 6.3175e-01, -1.1678e-01,  2.9775e-01,  2.2940e+01],\n",
       "        [ 6.5476e-01, -5.6029e-02,  1.4172e-01,  3.3769e+00],\n",
       "        [ 1.6036e-01, -1.9513e-01,  2.5080e-01,  3.3775e+01],\n",
       "        [ 5.4448e-01, -1.6957e-01,  2.0363e-01,  2.7362e+01],\n",
       "        [ 4.8460e-01,  5.3158e-02,  9.4846e-02,  2.5006e+01],\n",
       "        [ 7.6339e-01,  1.6804e-01,  1.3599e-01,  1.4881e+01],\n",
       "        [ 4.7920e-01,  1.3469e-01,  1.8289e-01,  4.4725e+00],\n",
       "        [ 5.4772e-01,  9.6025e-02,  1.6167e-01,  1.7874e+01],\n",
       "        [ 7.7392e-01, -1.6059e-02,  1.3208e-01,  1.0078e+01],\n",
       "        [ 3.5440e-01,  3.1873e-02,  2.9197e-01,  2.7155e+01],\n",
       "        [ 6.8637e-01,  1.4254e-01,  2.4793e-01,  8.0468e+00],\n",
       "        [ 8.0689e-01,  9.2401e-02,  2.9932e-01,  1.9360e+01],\n",
       "        [ 6.1000e-01,  5.4285e-02,  1.3451e-01,  2.1777e+01],\n",
       "        [ 5.1621e-01, -8.5863e-02,  1.0692e-01,  2.4025e+01],\n",
       "        [ 2.4622e-01, -1.6460e-01,  5.0494e-02,  3.0749e+01],\n",
       "        [ 2.5443e-01, -7.9858e-02,  1.2163e-01,  1.0620e+01],\n",
       "        [ 6.2766e-01,  1.3606e-01,  1.6957e-01,  1.7585e+01],\n",
       "        [ 4.9377e-01,  2.0000e-01,  3.0000e-01,  2.7145e+01],\n",
       "        [ 4.6396e-01,  1.6193e-01,  2.3294e-01,  7.9065e+00],\n",
       "        [ 4.1060e-01,  1.7214e-01,  2.6322e-01,  1.7198e+01],\n",
       "        [ 6.3917e-01,  4.6717e-02,  6.4109e-02,  2.3458e+01],\n",
       "        [ 5.7323e-01, -2.9478e-03,  1.0896e-01,  2.5827e+01],\n",
       "        [ 6.1069e-01, -6.4715e-02,  2.4631e-01,  3.1846e+01],\n",
       "        [ 8.1951e-01,  1.6133e-01,  1.0830e-01,  1.1918e+01],\n",
       "        [ 5.8647e-01,  9.8468e-02,  1.0560e-01,  2.2241e+01],\n",
       "        [ 4.7161e-01, -4.6422e-02,  2.4731e-01,  3.1468e+00],\n",
       "        [ 4.5977e-01,  8.5087e-02,  2.0438e-01,  3.2362e+01],\n",
       "        [ 4.3516e-01,  1.7431e-01,  9.4872e-02,  7.9695e+00],\n",
       "        [ 3.9829e-01, -3.2333e-05,  2.4488e-01,  1.1208e+01],\n",
       "        [ 2.8001e-01, -1.4237e-01,  7.4236e-02,  1.9691e+01],\n",
       "        [ 7.7283e-01,  1.6549e-01,  1.5692e-01,  2.6990e+01],\n",
       "        [ 1.9450e-01, -1.6526e-02,  1.6754e-01,  2.3885e+01],\n",
       "        [ 2.9120e-01, -9.6189e-02,  1.5903e-01,  3.3380e+00],\n",
       "        [ 5.5993e-01, -1.0800e-01,  7.7441e-02,  1.4749e+00],\n",
       "        [ 5.3561e-01, -5.9019e-02,  8.0451e-02,  9.0017e+00],\n",
       "        [ 3.9321e-01,  2.0000e-01,  1.7192e-01,  2.1397e+01],\n",
       "        [ 5.4572e-01,  2.0000e-01,  8.3216e-02,  2.1402e+01],\n",
       "        [ 6.0540e-01, -2.5492e-02,  2.4451e-01,  6.4324e+00],\n",
       "        [ 2.4694e-01, -1.8699e-01,  2.6644e-01,  7.7385e+00],\n",
       "        [ 8.5823e-01,  5.9186e-02,  2.2642e-01,  1.7313e+01],\n",
       "        [ 3.0154e-01,  1.9214e-01,  2.2851e-01,  2.4355e+01],\n",
       "        [ 7.9378e-01,  2.0000e-01,  1.3300e-01,  1.9916e+01],\n",
       "        [ 8.6897e-01,  1.7920e-01,  3.0000e-01,  2.3349e+01],\n",
       "        [ 8.8457e-01,  1.6321e-01,  1.1199e-01,  1.9740e+01],\n",
       "        [ 7.9322e-01,  2.0000e-01,  1.5301e-01,  2.3594e+01],\n",
       "        [ 7.8376e-01,  2.0000e-01,  1.5240e-01,  2.3638e+01],\n",
       "        [ 7.8677e-01,  2.0000e-01,  1.5259e-01,  2.3624e+01],\n",
       "        [ 7.5025e-01,  2.0000e-01,  3.0000e-01,  2.2068e+01],\n",
       "        [ 7.0819e-01,  1.6836e-01,  3.0000e-01,  2.4802e+01],\n",
       "        [ 6.6425e-01,  1.7280e-01,  3.0000e-01,  2.5020e+01],\n",
       "        [ 7.6061e-01,  2.0000e-01,  3.0000e-01,  2.2072e+01],\n",
       "        [ 7.5822e-01,  2.0000e-01,  3.0000e-01,  2.2067e+01],\n",
       "        [ 7.5898e-01,  2.0000e-01,  3.0000e-01,  2.2069e+01],\n",
       "        [ 6.0530e-01,  2.0000e-01,  7.4366e-02,  2.5405e+01],\n",
       "        [ 9.0000e-01,  1.9829e-01,  3.0000e-01,  2.5172e+01],\n",
       "        [ 5.1233e-01,  1.7634e-01,  3.0000e-01,  2.5444e+01],\n",
       "        [ 6.4648e-01,  2.0000e-01,  5.0000e-02,  2.5475e+01],\n",
       "        [ 6.4402e-01,  2.0000e-01,  5.0000e-02,  2.5482e+01],\n",
       "        [ 6.4478e-01,  2.0000e-01,  5.0000e-02,  2.5480e+01],\n",
       "        [ 9.0000e-01,  2.0000e-01,  3.0000e-01,  2.6057e+01],\n",
       "        [ 9.0000e-01,  1.5672e-01,  3.0000e-01,  2.4290e+01],\n",
       "        [ 9.0000e-01,  1.5609e-01,  3.0000e-01,  2.4606e+01],\n",
       "        [ 9.0000e-01,  2.0000e-01,  3.0000e-01,  2.6504e+01],\n",
       "        [ 9.0000e-01,  2.0000e-01,  3.0000e-01,  2.6472e+01],\n",
       "        [ 9.0000e-01,  2.0000e-01,  3.0000e-01,  2.6482e+01],\n",
       "        [ 7.0345e-01,  2.0000e-01,  2.2926e-01,  2.5227e+01],\n",
       "        [ 2.6930e-01,  1.1843e-01,  2.1226e-01,  3.4641e+01],\n",
       "        [ 9.0000e-01,  1.5672e-01,  3.0000e-01,  2.4290e+01],\n",
       "        [ 3.7455e-01,  1.8541e-01,  1.4924e-01,  2.7048e+01],\n",
       "        [ 3.5801e-01,  1.6955e-01,  1.4606e-01,  2.7138e+01],\n",
       "        [ 3.5810e-01,  1.7230e-01,  1.4467e-01,  2.7112e+01]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9108e+00, -1.6304e-01],\n",
       "        [ 1.8017e+00, -2.6843e-01],\n",
       "        [ 4.2945e-01, -3.4042e-01],\n",
       "        [ 4.4654e-02, -8.4389e-01],\n",
       "        [-9.7576e-01, -3.7701e-01],\n",
       "        [-5.8702e-02, -2.5200e-01],\n",
       "        [ 7.7013e-01, -1.1581e-01],\n",
       "        [ 1.6741e-01, -7.7385e-01],\n",
       "        [ 1.3113e+00, -1.6212e-01],\n",
       "        [ 7.7724e-01, -2.7060e-01],\n",
       "        [-6.2029e-01, -4.9247e-01],\n",
       "        [-5.8960e-02, -8.8871e-02],\n",
       "        [ 2.4007e+00, -2.4124e-01],\n",
       "        [ 2.1674e+00, -8.4050e-02],\n",
       "        [-4.4367e-01, -7.9206e-01],\n",
       "        [ 4.8342e-01, -2.5727e-01],\n",
       "        [ 1.9719e+00, -1.5712e-01],\n",
       "        [ 2.5570e+00, -5.4346e-02],\n",
       "        [ 1.5345e+00, -2.4041e-01],\n",
       "        [ 1.1445e+00, -1.1513e-01],\n",
       "        [-6.7834e-03, -1.0076e+00],\n",
       "        [ 2.0117e+00, -2.2303e-01],\n",
       "        [-2.3282e-01, -3.4492e-01],\n",
       "        [ 6.5260e-01, -3.7816e-01],\n",
       "        [ 1.0294e+00, -5.4807e-01],\n",
       "        [ 9.2709e-02, -7.7229e-01],\n",
       "        [ 1.8186e+00, -2.8142e-01],\n",
       "        [ 6.7494e-01, -2.2691e-01],\n",
       "        [ 1.8232e+00, -2.2079e-01],\n",
       "        [ 1.0729e+00, -1.6189e-01],\n",
       "        [-1.4375e-01, -9.8345e-01],\n",
       "        [ 1.4900e+00, -2.0259e-01],\n",
       "        [ 6.3148e-01, -5.4840e-01],\n",
       "        [ 9.8665e-01, -1.1309e-01],\n",
       "        [-3.1414e-01, -3.9636e-01],\n",
       "        [ 1.8880e+00, -1.6187e-01],\n",
       "        [ 8.2021e-01, -5.6311e-01],\n",
       "        [-8.7996e-02, -4.7094e-01],\n",
       "        [ 2.0525e+00, -1.1626e-01],\n",
       "        [ 2.9027e-02, -1.0063e+00],\n",
       "        [ 5.7279e-04, -4.8373e-01],\n",
       "        [ 8.5858e-01, -3.6348e-01],\n",
       "        [ 8.8596e-01, -5.0803e-01],\n",
       "        [ 2.3167e+00, -5.2919e-02],\n",
       "        [ 1.1430e+00, -1.3603e-01],\n",
       "        [ 1.9870e+00, -1.9683e-01],\n",
       "        [ 2.0299e+00, -1.9048e-01],\n",
       "        [-1.7561e-01, -1.9722e-01],\n",
       "        [-1.9726e-01, -7.4403e-01],\n",
       "        [-9.9625e-01, -3.8700e-01],\n",
       "        [ 8.0257e-01, -2.3464e-01],\n",
       "        [-3.8775e-01, -7.4605e-01],\n",
       "        [ 5.7011e-01, -6.9410e-01],\n",
       "        [-4.8496e-01, -1.1085e+00],\n",
       "        [ 1.3973e+00, -1.8386e-01],\n",
       "        [-1.6858e-01, -5.0467e-01],\n",
       "        [ 2.0647e+00, -2.6192e-01],\n",
       "        [ 7.1490e-01, -5.9190e-01],\n",
       "        [ 2.3099e+00, -1.6557e-01],\n",
       "        [ 2.4343e-02, -7.2939e-01],\n",
       "        [-3.2355e-01, -1.5335e-01],\n",
       "        [-8.2309e-02, -1.0722e+00],\n",
       "        [-2.0265e-01, -9.6671e-01],\n",
       "        [ 1.6101e+00, -2.4862e-01],\n",
       "        [ 2.1724e+00, -1.4205e-01],\n",
       "        [ 1.4377e+00, -1.8848e-01],\n",
       "        [ 2.0594e+00, -8.2818e-02],\n",
       "        [ 5.9526e-01, -1.9546e-01],\n",
       "        [ 1.5283e+00, -2.3519e-01],\n",
       "        [ 1.6958e+00, -1.9776e-01],\n",
       "        [ 2.0907e+00, -1.2127e-01],\n",
       "        [ 1.7804e+00, -1.4987e-01],\n",
       "        [ 4.1313e-01, -6.1589e-01],\n",
       "        [ 4.0641e-01, -8.1466e-01],\n",
       "        [ 1.6573e-01, -3.5981e-01],\n",
       "        [ 2.3373e+00, -7.1525e-02],\n",
       "        [ 2.4744e+00, -6.2582e-02],\n",
       "        [ 1.7411e+00, -2.2421e-01],\n",
       "        [ 2.1959e+00, -1.5570e-01],\n",
       "        [ 1.4512e+00, -3.1809e-01],\n",
       "        [ 1.0756e+00, -4.2521e-01],\n",
       "        [ 6.2453e-01, -6.5732e-01],\n",
       "        [ 1.9426e+00, -1.7194e-01],\n",
       "        [ 2.1201e+00, -1.0107e-01],\n",
       "        [-1.4131e-01, -1.9162e-01],\n",
       "        [ 1.9091e+00, -1.9436e-01],\n",
       "        [ 1.9164e+00, -1.8989e-01],\n",
       "        [ 7.9361e-01, -2.2713e-01],\n",
       "        [ 1.3560e-01, -6.3405e-01],\n",
       "        [ 2.5516e+00, -6.8336e-02],\n",
       "        [ 1.0458e+00, -3.7575e-01],\n",
       "        [-4.9311e-01, -2.1676e-01],\n",
       "        [-8.8901e-01, -1.4697e-01],\n",
       "        [ 1.8465e-01, -2.3511e-01],\n",
       "        [ 2.5682e+00, -9.9978e-02],\n",
       "        [ 2.6430e+00, -7.4494e-02],\n",
       "        [ 2.3574e-01, -2.2078e-01],\n",
       "        [-5.6710e-01, -6.1196e-01],\n",
       "        [ 1.8786e+00, -1.2848e-01],\n",
       "        [ 2.3807e+00, -1.2993e-01],\n",
       "        [ 2.4691e+00, -1.1511e-01],\n",
       "        [ 2.6446e+00, -4.0922e-02],\n",
       "        [ 2.3970e+00, -1.2033e-01],\n",
       "        [ 2.6023e+00, -6.1409e-02],\n",
       "        [ 2.6317e+00, -5.8296e-02],\n",
       "        [ 2.5189e+00, -4.5082e-02],\n",
       "        [ 2.5423e+00, -7.2888e-02],\n",
       "        [ 2.5436e+00, -3.6328e-02],\n",
       "        [ 2.5389e+00, -3.0071e-02],\n",
       "        [ 2.5902e+00, -6.7474e-02],\n",
       "        [ 6.6566e-01, -1.5743e-01],\n",
       "        [ 2.5429e+00, -6.7588e-02],\n",
       "        [ 2.5650e+00, -8.2163e-02],\n",
       "        [ 2.7132e+00, -3.1026e-02],\n",
       "        [ 2.4508e+00, -5.6917e-02],\n",
       "        [ 2.4514e+00, -1.2071e-01],\n",
       "        [ 2.5212e+00, -1.4256e-01],\n",
       "        [ 2.4291e+00, -1.1102e-01],\n",
       "        [ 2.7361e+00, -1.9102e-02],\n",
       "        [-2.0000e+00,  2.0000e+00],\n",
       "        [ 2.5785e+00, -4.8457e-02],\n",
       "        [ 2.7407e+00, -1.5117e-02],\n",
       "        [ 2.7404e+00, -1.5373e-02],\n",
       "        [ 2.7413e+00, -1.5626e-02],\n",
       "        [ 2.7001e+00, -2.2282e-02],\n",
       "        [ 1.9870e+00, -1.9683e-01],\n",
       "        [-2.0000e+00,  2.0000e+00],\n",
       "        [ 2.5603e+00, -4.8147e-02],\n",
       "        [ 2.5131e+00, -4.9930e-02],\n",
       "        [ 2.5186e+00, -5.0879e-02]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

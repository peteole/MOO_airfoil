{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.44476, 10.586571506034248]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "from botorch.models import SingleTaskGP, FixedNoiseGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition.multi_objective import ExpectedHypervolumeImprovement\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "import asyncio\n",
    "dtype = torch.float64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def x_to_filename(x):\n",
    "    return f'{x[0]}_{x[1]}_{x[2]}_{x[3]}.json'\n",
    "\n",
    "def filename_to_x(filename):\n",
    "    return [float(x) for x in filename[:-5].split('_')]\n",
    "\n",
    "async def evaluate_profile(x):\n",
    "    filename=x_to_filename(x)\n",
    "    #display(filename)\n",
    "    existing_result_files=os.listdir(\"case/results\")\n",
    "    existing_results_x=[filename_to_x(filename) for filename in existing_result_files]\n",
    "    distances=[torch.dist(torch.tensor(x),torch.tensor(existing_x)).item() for existing_x in existing_results_x]\n",
    "    #display(distances)\n",
    "    if min(distances)>0.001:\n",
    "        config=json.dumps({\n",
    "            'p':x[0],\n",
    "            'm':x[1],\n",
    "            't':x[2],\n",
    "            'a':x[3]\n",
    "        })\n",
    "        p=await asyncio.create_subprocess_shell(f'cd case; ./evaluate_airfoil.sh \\'{config}\\'',stdout=asyncio.subprocess.PIPE)\n",
    "        await p.wait()\n",
    "        #os.system(f'cd case; ./evaluate_airfoil.sh \\'{config}\\'')\n",
    "    min_distance_index=distances.index(min(distances))\n",
    "    with open(\"case/results/\"+existing_result_files[min_distance_index]) as file:\n",
    "        result=json.load(file)\n",
    "        #display(result)\n",
    "        return [result['C_L'],result['C_L']/result['C_D']]\n",
    "\n",
    "\n",
    "await evaluate_profile([0.42,0.05,0.18,14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.2000e-01,  1.0000e-01,  1.8000e-01,  1.2000e+01],\n",
       "        [ 1.6297e-01, -1.9246e-01,  6.6998e-02,  2.2169e+00],\n",
       "        [ 4.2000e-01,  1.0000e-01,  1.8000e-01,  1.5000e+01],\n",
       "        [ 4.2000e-01,  1.0000e-01,  1.8000e-01,  2.0000e+01],\n",
       "        [ 4.0000e-01,  5.0000e-02,  1.5000e-01,  5.0000e+01],\n",
       "        [ 5.2345e-01,  4.2727e-02,  1.9550e-01,  1.5996e+01],\n",
       "        [ 4.0000e-01,  5.0000e-02,  1.5000e-01,  6.0000e+01],\n",
       "        [ 4.0000e-01,  5.0000e-02,  1.5000e-01,  4.0000e+01],\n",
       "        [ 3.3545e-01,  3.0853e-02,  2.7415e-01,  2.4670e+01],\n",
       "        [ 2.4970e-01, -5.1559e-02,  1.4601e-01,  3.0229e+00],\n",
       "        [ 4.1784e-01, -6.5921e-02,  2.1528e-01,  2.2247e+01],\n",
       "        [ 4.0000e-01,  5.0000e-02,  1.5000e-01,  2.0000e+01],\n",
       "        [ 4.2000e-01,  1.0000e-01,  1.8000e-01,  1.0000e-02],\n",
       "        [ 4.2000e-01,  1.0000e-01,  3.0000e-01,  3.0000e+01],\n",
       "        [ 4.2000e-01,  5.0000e-02,  1.8000e-01,  1.1000e+01],\n",
       "        [ 1.9553e-01,  1.3699e-01,  7.0834e-02,  6.9063e+00],\n",
       "        [ 1.9088e-01,  1.6903e-01,  1.5340e-01,  1.8939e+01],\n",
       "        [ 7.9877e-01,  6.7014e-02,  2.2157e-01,  2.7539e+01],\n",
       "        [ 4.2000e-01,  0.0000e+00,  1.2000e-01,  1.2000e+01],\n",
       "        [ 4.0000e-01,  5.0000e-02,  1.5000e-01,  1.5000e+01]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_lims=[(0.1,0.9),(-0.2,0.2),(0.05,0.3),(0.01,35)]\n",
    "\n",
    "# initial_X = torch.rand(6,4)\n",
    "# for d in range(4):\n",
    "#     initial_X[:,d]=x_lims[d][0]+initial_X[:,d]*(x_lims[d][1]-x_lims[d][0])\n",
    "\n",
    "# get initial X from filenames in case/results folder\n",
    "initial_X=torch.tensor([filename_to_x(filename) for filename in os.listdir(\"case/results\")],dtype=dtype,device=device)\n",
    "# take six random points from the initial X\n",
    "initial_X = initial_X[torch.randperm(initial_X.shape[0])[:20]]\n",
    "\n",
    "display(initial_X)\n",
    "y=await asyncio.gather(*[evaluate_profile(x.tolist()) for x in initial_X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e-01, -2.0000e-01,  5.0000e-02,  1.0000e-02],\n",
       "        [ 9.0000e-01,  2.0000e-01,  3.0000e-01,  3.5000e+01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = torch.stack([torch.tensor(x_lims)[:,0], torch.tensor(x_lims)[:,1]])\n",
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olep/.local/lib/python3.10/site-packages/botorch/acquisition/multi_objective/analytic.py:131: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ref_point = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4290,  0.1162,  0.2965, 19.9220], dtype=torch.float64) :  tensor(3.5622, dtype=torch.float64)\n",
      "tensor([[ 2.0016, 22.7987]], dtype=torch.float64, grad_fn=<TransposeBackward0>) +- tensor([[0.3329, 3.0569]], dtype=torch.float64, grad_fn=<SqrtBackward0>)\n",
      "[1.90987, 14.748828121983427]\n",
      "tensor([[ 1.6956, 12.4764],\n",
      "        [-0.5486, -1.7773],\n",
      "        [ 1.8373, 17.3114],\n",
      "        [ 2.0099, 25.4021],\n",
      "        [ 1.2502,  1.7287],\n",
      "        [ 1.3467,  8.2575],\n",
      "        [ 0.8679,  1.0383],\n",
      "        [ 1.5748,  3.0283],\n",
      "        [ 1.4417,  6.1830],\n",
      "        [-0.1452, -1.0555],\n",
      "        [ 0.4364,  0.7918],\n",
      "        [ 1.6922, 12.6588],\n",
      "        [ 0.8315,  6.2962],\n",
      "        [ 1.8565, 11.3555],\n",
      "        [ 1.2629,  8.9512],\n",
      "        [ 1.4649,  8.3809],\n",
      "        [ 2.0008,  9.3529],\n",
      "        [ 1.8688, 10.5315],\n",
      "        [ 0.9425,  5.2468],\n",
      "        [ 1.5422, 12.6082],\n",
      "        [ 1.9099, 14.7488]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olep/.local/lib/python3.10/site-packages/botorch/acquisition/multi_objective/analytic.py:131: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ref_point = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3121,  0.1226,  0.1505, 19.9295], dtype=torch.float64) :  tensor(2.4400, dtype=torch.float64)\n",
      "tensor([[ 1.9633, 21.3649]], dtype=torch.float64, grad_fn=<TransposeBackward0>) +- tensor([[0.2936, 3.5038]], dtype=torch.float64, grad_fn=<SqrtBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n",
      "Warning : Cannot apply Blossom: odd number of triangles (26679) in surface 1\n",
      "Warning : ------------------------------\n",
      "Warning : Mesh generation error summary\n",
      "Warning :     1 warning\n",
      "Warning :     0 errors\n",
      "Warning : Check the full log for details\n",
      "Warning : ------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.69216, 12.658761922573408]\n",
      "tensor([[ 1.6956, 12.4764],\n",
      "        [-0.5486, -1.7773],\n",
      "        [ 1.8373, 17.3114],\n",
      "        [ 2.0099, 25.4021],\n",
      "        [ 1.2502,  1.7287],\n",
      "        [ 1.3467,  8.2575],\n",
      "        [ 0.8679,  1.0383],\n",
      "        [ 1.5748,  3.0283],\n",
      "        [ 1.4417,  6.1830],\n",
      "        [-0.1452, -1.0555],\n",
      "        [ 0.4364,  0.7918],\n",
      "        [ 1.6922, 12.6588],\n",
      "        [ 0.8315,  6.2962],\n",
      "        [ 1.8565, 11.3555],\n",
      "        [ 1.2629,  8.9512],\n",
      "        [ 1.4649,  8.3809],\n",
      "        [ 2.0008,  9.3529],\n",
      "        [ 1.8688, 10.5315],\n",
      "        [ 0.9425,  5.2468],\n",
      "        [ 1.5422, 12.6082],\n",
      "        [ 1.9099, 14.7488],\n",
      "        [ 1.6922, 12.6588]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olep/.local/lib/python3.10/site-packages/botorch/acquisition/multi_objective/analytic.py:131: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ref_point = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5542,  0.1062,  0.1628, 20.0149], dtype=torch.float64) :  tensor(3.3208, dtype=torch.float64)\n",
      "tensor([[ 1.9985, 23.0282]], dtype=torch.float64, grad_fn=<TransposeBackward0>) +- tensor([[0.3060, 2.9089]], dtype=torch.float64, grad_fn=<SqrtBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : Extrusion of periodic curves is not supported with the built-in kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.00995, 25.40205117187253]\n",
      "tensor([[ 1.6956, 12.4764],\n",
      "        [-0.5486, -1.7773],\n",
      "        [ 1.8373, 17.3114],\n",
      "        [ 2.0099, 25.4021],\n",
      "        [ 1.2502,  1.7287],\n",
      "        [ 1.3467,  8.2575],\n",
      "        [ 0.8679,  1.0383],\n",
      "        [ 1.5748,  3.0283],\n",
      "        [ 1.4417,  6.1830],\n",
      "        [-0.1452, -1.0555],\n",
      "        [ 0.4364,  0.7918],\n",
      "        [ 1.6922, 12.6588],\n",
      "        [ 0.8315,  6.2962],\n",
      "        [ 1.8565, 11.3555],\n",
      "        [ 1.2629,  8.9512],\n",
      "        [ 1.4649,  8.3809],\n",
      "        [ 2.0008,  9.3529],\n",
      "        [ 1.8688, 10.5315],\n",
      "        [ 0.9425,  5.2468],\n",
      "        [ 1.5422, 12.6082],\n",
      "        [ 1.9099, 14.7488],\n",
      "        [ 1.6922, 12.6588],\n",
      "        [ 2.0099, 25.4021]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from botorch.utils.multi_objective.box_decompositions.non_dominated import FastNondominatedPartitioning\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "from botorch.optim import optimize_acqf\n",
    "train_X=initial_X\n",
    "train_Y = torch.tensor(y,dtype=dtype,device=device)\n",
    "#print(train_X)\n",
    "#print(train_Y)\n",
    "N_BATCH=3\n",
    "for iteration in range(1, N_BATCH + 1):\n",
    "    #gp = SingleTaskGP(train_X, train_Y)\n",
    "    train_Yvar = torch.full_like(train_Y, 0.01)\n",
    "    gp= FixedNoiseGP(train_X, train_Y, train_Yvar)\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    #test_X=torch.rand(1,4)\n",
    "    #print(test_X,\": \",gp.posterior(train_X).mean,\"+-\",gp.posterior(train_X).variance.sqrt())\n",
    "\n",
    "    #\n",
    "\n",
    "    #acquisition_function = UpperConfidenceBound(gp, beta=0.1)\n",
    "    partitioning=FastNondominatedPartitioning(ref_point=torch.tensor([0.0, 0.0]),Y=train_Y)\n",
    "    acquisition_function = ExpectedHypervolumeImprovement(\n",
    "        gp, ref_point=torch.tensor([0.0, 0.0]),\n",
    "        partitioning=partitioning)\n",
    "\n",
    "    candidate, acq_value = optimize_acqf(\n",
    "        acquisition_function, bounds=bounds, q=1, num_restarts=1, batch_initial_conditions=train_X\n",
    "    )\n",
    "    print(candidate,\": \",acq_value)\n",
    "    predicted_Y=gp.posterior(candidate.unsqueeze(0)).mean\n",
    "    prediceted_Y_var=gp.posterior(candidate.unsqueeze(0)).variance\n",
    "    print(predicted_Y,\"+-\",prediceted_Y_var.sqrt())\n",
    "    actual_value=await evaluate_profile(candidate.tolist())\n",
    "    print(actual_value)\n",
    "    # add new data to training data\n",
    "    train_X = torch.cat([train_X, candidate.unsqueeze(0)])\n",
    "    train_Y = torch.cat([train_Y, torch.tensor(actual_value,dtype=dtype,device=device).unsqueeze(0)])\n",
    "    print(train_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
